# 心理健康聊天机器人后端系统详细技术文档

## 项目概述

### 项目背景
心理健康聊天机器人后端系统是一个基于大语言模型的智能心理咨询平台，旨在为用户提供专业、安全、可靠的心理健康服务。系统采用现代化的微服务架构，集成了先进的自然语言处理技术、向量数据库、智能路由等核心技术，实现了从用户交互到专业心理咨询的全流程自动化处理。

### 技术愿景
- **智能化**：基于DeepSeek大语言模型，提供高质量的心理咨询对话
- **安全性**：实现危机识别与干预，保障用户心理安全
- **可扩展性**：模块化设计，支持功能快速迭代和扩展
- **高性能**：向量化检索和缓存机制，确保响应速度
- **专业性**：融合心理学专业知识，提供共情式对话体验

### 核心价值
1. **24/7可用性**：全天候提供心理健康支持服务
2. **隐私保护**：严格的数据安全和用户隐私保护机制
3. **个性化服务**：基于用户历史和情感状态的个性化响应
4. **专业标准**：符合心理咨询行业标准和伦理规范
5. **可访问性**：降低心理健康服务的门槛和成本

## 系统架构设计

### 整体架构

```
┌─────────────────────────────────────────────────────────────┐
│                    前端用户界面层                              │
├─────────────────────────────────────────────────────────────┤
│                    API网关层                                 │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │  认证服务    │ │  会话管理    │ │  聊天服务    │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    核心业务逻辑层                             │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │ 心理咨询控制器│ │  智能路由    │ │  危机识别    │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │  意图分析    │ │  文档检索    │ │  结果重排    │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    数据处理层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │  向量存储    │ │  文档加载器  │ │  流式服务    │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
├─────────────────────────────────────────────────────────────┤
│                    数据存储层                                │
│  ┌─────────────┐ ┌─────────────┐ ┌─────────────┐           │
│  │  MySQL数据库 │ │  Chroma向量库│ │  文件存储    │           │
│  └─────────────┘ └─────────────┘ └─────────────┘           │
└─────────────────────────────────────────────────────────────┘
```

### 技术栈选型

#### 后端框架
- **FastAPI**: 现代化的Python Web框架，支持自动API文档生成
- **SQLAlchemy**: 强大的ORM框架，支持多种数据库
- **Pydantic**: 数据验证和序列化库
- **LangChain**: 大语言模型应用开发框架

#### 数据库技术
- **MySQL**: 主数据库，存储用户信息、会话记录等结构化数据
- **Chroma**: 向量数据库，存储文档嵌入向量用于语义检索
- **Redis**: 缓存数据库（规划中），提升系统性能

#### AI/ML技术
- **DeepSeek-Chat**: 主要的大语言模型，提供对话生成能力
- **OpenAI Embeddings**: 文本向量化模型
- **HuggingFace Transformers**: 本地嵌入模型支持
- **jieba**: 中文分词工具，用于文本处理

#### 开发工具
- **Poetry**: Python依赖管理
- **pytest**: 单元测试框架
- **Black**: 代码格式化工具
- **mypy**: 静态类型检查

## 核心模块详细设计

### 1. 向量化与索引模块

#### 模块概述
向量化与索引模块是系统的核心基础设施，负责将文本内容转换为高维向量表示，并建立高效的索引结构以支持语义相似度检索。

#### 技术实现

**文件位置**: `core/vector_store.py`

**核心功能**:
1. **动态模型加载**: 支持OpenAI和HuggingFace两种嵌入模型
2. **设备自适应**: 自动检测并选择最优计算设备（CUDA/MPS/CPU）
3. **向量存储**: 基于Chroma的持久化向量数据库
4. **容错机制**: 模型加载失败时的降级策略

**关键代码结构**:
```python
def get_embedding_model():
    """动态加载嵌入模型"""
    config = get_config()
    if config.embedding.provider == "openai":
        return OpenAIEmbeddings(model=config.embedding.model)
    else:
        return HuggingFaceEmbeddings(
            model_name=config.embedding.model,
            model_kwargs={'device': _get_device()}
        )

def get_vector_store():
    """获取向量存储实例"""
    embedding_model = get_embedding_model()
    return Chroma(
        persist_directory=config.chroma.persist_directory,
        embedding_function=embedding_model
    )
```

**性能优化**:
- 模型缓存机制，避免重复加载
- 批量向量化处理，提升吞吐量
- 异步处理支持，减少阻塞时间

#### 配置参数
```yaml
embedding:
  provider: "openai"  # openai | huggingface
  model: "text-embedding-ada-002"
  batch_size: 100
  max_retries: 3

chroma:
  persist_directory: "./chroma_db"
  collection_name: "psychological_knowledge"
  distance_metric: "cosine"
```

### 2. 混合搜索模块

#### 模块概述
混合搜索模块结合了向量语义搜索和传统关键词搜索的优势，通过多种检索策略的融合，提供更准确和全面的文档检索结果。

#### 当前实现状态
- ✅ **向量搜索**: 基于语义相似度的文档检索
- ⚠️ **关键词搜索**: 需要集成BM25算法
- ⚠️ **结果融合**: 需要实现加权融合策略

#### 技术方案设计

**向量搜索实现**:
```python
def vector_search(query: str, k: int = 5) -> List[Document]:
    """基于向量相似度的文档检索"""
    vector_store = get_vector_store()
    return vector_store.similarity_search(query, k=k)
```

**关键词搜索设计**（待实现）:
```python
from rank_bm25 import BM25Okapi

class KeywordSearcher:
    def __init__(self, documents: List[str]):
        self.tokenized_docs = [jieba.lcut(doc) for doc in documents]
        self.bm25 = BM25Okapi(self.tokenized_docs)
    
    def search(self, query: str, k: int = 5) -> List[Document]:
        """BM25关键词搜索"""
        tokenized_query = jieba.lcut(query)
        scores = self.bm25.get_scores(tokenized_query)
        top_indices = np.argsort(scores)[::-1][:k]
        return [self.documents[i] for i in top_indices]
```

**融合策略设计**（待实现）:
```python
def hybrid_search(query: str, k: int = 5, alpha: float = 0.7) -> List[Document]:
    """混合搜索：向量搜索 + 关键词搜索"""
    vector_results = vector_search(query, k=k*2)
    keyword_results = keyword_search(query, k=k*2)
    
    # 加权融合
    fused_results = fuse_results(
        vector_results, keyword_results, 
        alpha=alpha, beta=1-alpha
    )
    return fused_results[:k]
```

#### 优化建议
1. **实现BM25算法**: 集成rank_bm25库
2. **结果融合策略**: 实现RRF（Reciprocal Rank Fusion）算法
3. **查询扩展**: 基于同义词和相关词的查询扩展
4. **缓存机制**: 热门查询结果缓存

### 3. 结果精排模块

#### 模块概述
结果精排模块对初步检索到的文档进行二次排序，通过更精细的相关性计算，确保最相关的内容排在前面。

#### 技术实现

**文件位置**: `core/psychological_tools.py`

**核心算法**:
```python
@tool
def rerank_documents(user_input: str, documents: List[str]) -> str:
    """使用TF-IDF和余弦相似度重排序文档"""
    try:
        if not documents:
            return "没有找到相关文档"
        
        # 中文分词
        def tokenize_chinese(text):
            return ' '.join(jieba.lcut(text))
        
        # 处理用户输入和文档
        processed_input = tokenize_chinese(user_input)
        processed_docs = [tokenize_chinese(doc) for doc in documents]
        
        # TF-IDF向量化
        vectorizer = TfidfVectorizer(
            stop_words=None,
            max_features=1000,
            ngram_range=(1, 2)
        )
        
        # 构建语料库
        corpus = [processed_input] + processed_docs
        tfidf_matrix = vectorizer.fit_transform(corpus)
        
        # 计算余弦相似度
        query_vector = tfidf_matrix[0]
        doc_vectors = tfidf_matrix[1:]
        similarities = cosine_similarity(query_vector, doc_vectors).flatten()
        
        # 排序并返回前5个最相关的文档
        ranked_indices = similarities.argsort()[::-1][:5]
        ranked_docs = [documents[i] for i in ranked_indices]
        
        return "\n\n".join(ranked_docs)
        
    except Exception as e:
        return f"重排序过程中出现错误: {str(e)}"
```

#### 算法优势
1. **TF-IDF特征提取**: 捕获词汇重要性和文档特征
2. **N-gram支持**: 考虑词汇组合的语义信息
3. **余弦相似度**: 标准化的相似度计算方法
4. **中文优化**: 专门针对中文文本的分词处理

#### 性能指标
- **准确率**: 相关文档排在前位的比例
- **召回率**: 检索到的相关文档占总相关文档的比例
- **响应时间**: 重排序处理的平均耗时
- **用户满意度**: 基于用户反馈的质量评估

#### 优化方向
1. **深度学习重排序**: 集成BERT等预训练模型
2. **多特征融合**: 结合语义、语法、情感等多维特征
3. **个性化排序**: 基于用户历史和偏好的个性化排序
4. **实时学习**: 基于用户反馈的在线学习机制

### 4. 数据处理流水线模块

#### 模块概述
数据处理流水线负责将各种格式的文档转换为系统可处理的标准格式，包括文档解析、内容清洗、文本分块等预处理步骤。

#### 当前实现状态
- ⚠️ **配置支持**: 已有文本分割配置参数
- ❌ **多格式支持**: 缺少PDF、Word、TXT等格式处理器
- ❌ **内容清洗**: 缺少文本清洗和标准化流程
- ❌ **分块策略**: 缺少智能分块算法

#### 技术方案设计

**配置参数**:
```yaml
text_splitter:
  chunk_size: 1000
  chunk_overlap: 200
  separators: ["\n\n", "\n", "。", "！", "？"]
```

**文档处理器设计**:
```python
class DocumentProcessor:
    """文档处理器基类"""
    
    def process(self, file_path: str) -> List[Document]:
        """处理文档并返回分块结果"""
        content = self.extract_content(file_path)
        cleaned_content = self.clean_content(content)
        chunks = self.split_content(cleaned_content)
        return [Document(page_content=chunk) for chunk in chunks]
    
    def extract_content(self, file_path: str) -> str:
        """提取文档内容"""
        raise NotImplementedError
    
    def clean_content(self, content: str) -> str:
        """清洗文档内容"""
        # 移除多余空白字符
        content = re.sub(r'\s+', ' ', content)
        # 移除特殊字符
        content = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9\s\.,!?;:]', '', content)
        return content.strip()
    
    def split_content(self, content: str) -> List[str]:
        """智能分块"""
        splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.config.chunk_size,
            chunk_overlap=self.config.chunk_overlap,
            separators=self.config.separators
        )
        return splitter.split_text(content)

class PDFProcessor(DocumentProcessor):
    """PDF文档处理器"""
    
    def extract_content(self, file_path: str) -> str:
        import PyPDF2
        with open(file_path, 'rb') as file:
            reader = PyPDF2.PdfReader(file)
            content = ""
            for page in reader.pages:
                content += page.extract_text()
        return content

class WordProcessor(DocumentProcessor):
    """Word文档处理器"""
    
    def extract_content(self, file_path: str) -> str:
        from docx import Document
        doc = Document(file_path)
        content = ""
        for paragraph in doc.paragraphs:
            content += paragraph.text + "\n"
        return content
```

**流水线管理器**:
```python
class DocumentPipeline:
    """文档处理流水线"""
    
    def __init__(self):
        self.processors = {
            '.pdf': PDFProcessor(),
            '.docx': WordProcessor(),
            '.txt': TextProcessor()
        }
    
    def process_document(self, file_path: str) -> List[Document]:
        """处理单个文档"""
        file_ext = Path(file_path).suffix.lower()
        processor = self.processors.get(file_ext)
        
        if not processor:
            raise ValueError(f"不支持的文件格式: {file_ext}")
        
        return processor.process(file_path)
    
    def process_directory(self, directory: str) -> List[Document]:
        """批量处理目录下的文档"""
        documents = []
        for file_path in Path(directory).rglob('*'):
            if file_path.is_file() and file_path.suffix in self.processors:
                try:
                    docs = self.process_document(str(file_path))
                    documents.extend(docs)
                except Exception as e:
                    logger.error(f"处理文档失败 {file_path}: {e}")
        return documents
```

#### 实现优先级
1. **高优先级**: PDF和TXT处理器
2. **中优先级**: Word和Markdown处理器
3. **低优先级**: Excel和PowerPoint处理器

### 5. 智能路由模块

#### 模块概述
智能路由模块是系统的核心调度中心，负责分析用户意图，并根据不同的意图类型选择相应的处理流程。

#### 技术实现

**文件位置**: `core/psychological_controller.py`

**核心架构**:
```python
class PsychologicalChatController:
    """心理咨询聊天控制器"""
    
    def __init__(self):
        self.tools = [
            analyze_intent,
            check_safety,
            retrieve_documents,
            rerank_documents,
            generate_answer
        ]
        self.llm = get_llm()
        self.agent = create_tool_calling_agent(self.llm, self.tools)
    
    async def process_message_stream(self, user_input: str, session_id: str):
        """流式处理用户消息"""
        try:
            # 1. 意图分析
            yield self._create_stream_chunk("正在分析您的问题...")
            intent_result = await self._analyze_intent(user_input)
            
            # 2. 安全检查
            if intent_result.get('intent') == 'crisis':
                yield self._create_stream_chunk("检测到紧急情况，正在处理...")
                safety_result = await self._check_safety(user_input)
                if safety_result.get('risk_level') in ['high', 'medium']:
                    yield self._create_stream_chunk(safety_result.get('response'))
                    return
            
            # 3. 文档检索
            yield self._create_stream_chunk("正在搜索相关资料...")
            documents = await self._retrieve_documents(user_input, intent_result)
            
            # 4. 文档重排序
            if documents:
                yield self._create_stream_chunk("正在优化搜索结果...")
                ranked_docs = await self._rerank_documents(user_input, documents)
            else:
                ranked_docs = ""
            
            # 5. 生成回答
            yield self._create_stream_chunk("正在生成回答...")
            async for chunk in self._generate_answer_stream(
                user_input, intent_result, ranked_docs, session_id
            ):
                yield chunk
                
        except asyncio.TimeoutError:
            yield self._create_error_chunk("处理超时，请稍后重试")
        except Exception as e:
            yield self._create_error_chunk(f"处理过程中出现错误: {str(e)}")
```

**意图分析流程**:
```python
@tool
def analyze_intent(user_input: str) -> str:
    """分析用户意图和情感状态"""
    crisis_keywords = [
        "自杀", "结束生命", "不想活", "死了算了", "活着没意思",
        "自残", "伤害自己", "想死", "轻生", "了结"
    ]
    
    consultation_keywords = [
        "抑郁", "焦虑", "压力", "失眠", "情绪", "心理", "咨询",
        "治疗", "症状", "诊断", "药物", "心理医生"
    ]
    
    knowledge_keywords = [
        "什么是", "如何", "为什么", "怎么办", "方法", "建议",
        "原因", "症状", "表现", "特点"
    ]
    
    # 危机检测
    if any(keyword in user_input for keyword in crisis_keywords):
        return json.dumps({
            "intent": "crisis",
            "confidence": 0.9,
            "emotion": "negative",
            "urgency": "high"
        }, ensure_ascii=False)
    
    # 咨询意图检测
    elif any(keyword in user_input for keyword in consultation_keywords):
        return json.dumps({
            "intent": "consultation",
            "confidence": 0.8,
            "emotion": "neutral",
            "urgency": "medium"
        }, ensure_ascii=False)
    
    # 知识查询意图
    elif any(keyword in user_input for keyword in knowledge_keywords):
        return json.dumps({
            "intent": "knowledge",
            "confidence": 0.7,
            "emotion": "neutral",
            "urgency": "low"
        }, ensure_ascii=False)
    
    # 默认为闲聊
    else:
        return json.dumps({
            "intent": "chat",
            "confidence": 0.6,
            "emotion": "neutral",
            "urgency": "low"
        }, ensure_ascii=False)
```

**路由决策逻辑**:
1. **危机路由**: 立即触发安全检查和危机干预
2. **咨询路由**: 检索专业资料，生成专业建议
3. **知识路由**: 搜索知识库，提供科普信息
4. **闲聊路由**: 进行日常对话，建立信任关系

#### 性能优化
1. **异步处理**: 所有工具调用都采用异步模式
2. **流式响应**: 实时返回处理进度和结果
3. **缓存机制**: 缓存常见意图分析结果
4. **超时控制**: 防止长时间阻塞用户请求

### 6. 用户认证与会话管理

#### 用户认证模块

**文件位置**: `api/auth.py`

**核心功能**:
1. **用户注册**: 邮箱唯一性验证、密码加密存储
2. **用户登录**: 身份验证、JWT令牌生成
3. **令牌管理**: 访问令牌和刷新令牌的生命周期管理
4. **密码安全**: bcrypt加密、密码强度验证
5. **匿名支持**: 支持匿名用户访问部分功能

**安全机制**:
```python
# 密码加密
def hash_password(password: str) -> str:
    """使用bcrypt加密密码"""
    salt = bcrypt.gensalt()
    return bcrypt.hashpw(password.encode('utf-8'), salt).decode('utf-8')

# JWT令牌生成
def create_access_token(data: dict, expires_delta: timedelta = None):
    """创建访问令牌"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=30)
    
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, SECRET_KEY, algorithm=ALGORITHM)

# 用户身份验证
async def get_current_user(token: str = Depends(oauth2_scheme)):
    """获取当前用户"""
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )
    
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=[ALGORITHM])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
    
    user = get_user_by_id(user_id)
    if user is None:
        raise credentials_exception
    return user
```

#### 会话管理模块

**文件位置**: `models/conversation.py`, `services/conversation_service.py`

**数据模型**:
```python
class Conversation(Base):
    """对话会话模型"""
    __tablename__ = "conversations"
    
    conversation_id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    user_id = Column(String(36), ForeignKey("users.user_id"), nullable=True)
    title = Column(String(200), nullable=False, default="新对话")
    message_count = Column(Integer, default=0)
    is_active = Column(Boolean, default=True)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    last_message_at = Column(DateTime, nullable=True)
    
    # 关系
    user = relationship("User", back_populates="conversations")
    messages = relationship("Message", back_populates="conversation", cascade="all, delete-orphan")

class Message(Base):
    """消息模型"""
    __tablename__ = "messages"
    
    message_id = Column(String(36), primary_key=True, default=lambda: str(uuid.uuid4()))
    conversation_id = Column(String(36), ForeignKey("conversations.conversation_id"), nullable=False)
    role = Column(Enum(MessageRole), nullable=False)  # user, assistant
    content = Column(Text, nullable=False)
    model_name = Column(String(100), nullable=True)
    temperature = Column(Float, nullable=True)
    message_metadata = Column(JSON, nullable=True)
    feedback = Column(Integer, nullable=True)  # -1, 0, 1
    created_at = Column(DateTime, default=datetime.utcnow)
    
    # 关系
    conversation = relationship("Conversation", back_populates="messages")
```

**服务层功能**:
```python
class ConversationService:
    """会话管理服务"""
    
    def create_conversation(self, user_id: str = None, title: str = "新对话") -> Conversation:
        """创建新会话"""
        conversation = Conversation(
            user_id=user_id,
            title=title
        )
        self.db.add(conversation)
        self.db.commit()
        return conversation
    
    def get_user_conversations(self, user_id: str, limit: int = 20) -> List[Conversation]:
        """获取用户会话列表"""
        return self.db.query(Conversation)\
            .filter(Conversation.user_id == user_id)\
            .filter(Conversation.is_active == True)\
            .order_by(Conversation.last_message_at.desc())\
            .limit(limit)\
            .all()
    
    def add_message(self, conversation_id: str, role: MessageRole, 
                   content: str, metadata: dict = None) -> Message:
        """添加消息到会话"""
        message = Message(
            conversation_id=conversation_id,
            role=role,
            content=content,
            message_metadata=metadata
        )
        
        # 更新会话信息
        conversation = self.get_conversation(conversation_id)
        conversation.message_count += 1
        conversation.last_message_at = datetime.utcnow()
        
        self.db.add(message)
        self.db.commit()
        return message
    
    def delete_conversation(self, conversation_id: str, user_id: str) -> bool:
        """删除会话（软删除）"""
        conversation = self.db.query(Conversation)\
            .filter(Conversation.conversation_id == conversation_id)\
            .filter(Conversation.user_id == user_id)\
            .first()
        
        if conversation:
            conversation.is_active = False
            self.db.commit()
            return True
        return False
```

### 7. 危机识别与干预模块

#### 模块概述
危机识别与干预模块是系统的安全保障核心，负责实时监测用户的心理状态，识别潜在的自伤或自杀风险，并提供及时的干预措施。

#### 技术实现

**文件位置**: `core/psychological_tools.py`

**风险评估算法**:
```python
@tool
def check_safety(user_input: str) -> str:
    """检查用户输入的安全性，识别自伤或自杀风险"""
    
    # 高风险关键词
    high_risk_keywords = [
        "想死", "自杀", "结束生命", "不想活了", "死了算了",
        "跳楼", "上吊", "割腕", "服毒", "了结自己"
    ]
    
    # 中风险关键词
    medium_risk_keywords = [
        "活着没意思", "生无可恋", "绝望", "痛苦", "煎熬",
        "解脱", "一了百了", "消失", "离开这个世界"
    ]
    
    # 自伤关键词
    self_harm_keywords = [
        "自残", "伤害自己", "割伤", "烫伤", "撞墙",
        "自虐", "惩罚自己", "让自己受伤"
    ]
    
    user_input_lower = user_input.lower()
    
    # 高风险检测
    high_risk_count = sum(1 for keyword in high_risk_keywords 
                         if keyword in user_input_lower)
    
    # 中风险检测
    medium_risk_count = sum(1 for keyword in medium_risk_keywords 
                           if keyword in user_input_lower)
    
    # 自伤风险检测
    self_harm_count = sum(1 for keyword in self_harm_keywords 
                         if keyword in user_input_lower)
    
    # 风险等级判定
    if high_risk_count >= 2 or (high_risk_count >= 1 and medium_risk_count >= 1):
        risk_level = "high"
        response = generate_crisis_response("high")
    elif high_risk_count >= 1 or medium_risk_count >= 2 or self_harm_count >= 1:
        risk_level = "medium"
        response = generate_crisis_response("medium")
    elif medium_risk_count >= 1:
        risk_level = "low"
        response = generate_crisis_response("low")
    else:
        risk_level = "safe"
        response = "用户输入安全"
    
    return json.dumps({
        "risk_level": risk_level,
        "high_risk_count": high_risk_count,
        "medium_risk_count": medium_risk_count,
        "self_harm_count": self_harm_count,
        "response": response,
        "timestamp": datetime.now().isoformat()
    }, ensure_ascii=False)

def generate_crisis_response(risk_level: str) -> str:
    """生成危机干预响应"""
    
    if risk_level == "high":
        return """
我非常担心您现在的状态。您的生命很宝贵，请不要放弃。

🚨 紧急求助热线：
• 全国心理危机干预热线：400-161-9995
• 北京危机干预热线：400-161-9995
• 上海心理援助热线：021-64383562

请立即联系以上热线或前往最近的医院急诊科。
如果您身边有信任的朋友或家人，也请立即联系他们。

您并不孤单，总有人愿意帮助您度过这个困难时期。
        """.strip()
    
    elif risk_level == "medium":
        return """
我能感受到您现在很痛苦，这种感受一定很难受。

💙 专业支持资源：
• 心理咨询热线：400-161-9995
• 在线心理咨询平台：壹心理、简单心理
• 当地心理健康中心

请记住：
• 这种痛苦的感觉是暂时的
• 寻求专业帮助是勇敢的表现
• 您值得被关爱和支持

如果情况紧急，请不要犹豫立即拨打急救电话120。
        """.strip()
    
    elif risk_level == "low":
        return """
我注意到您可能正在经历一些困难。这很正常，每个人都会有低落的时候。

🌟 建议您：
• 与信任的朋友或家人交流
• 尝试一些放松技巧，如深呼吸或冥想
• 保持规律的作息和适量运动
• 如果持续感到困扰，考虑寻求专业心理咨询

记住，寻求帮助是力量的体现，不是软弱。
        """.strip()
    
    return "请注意您的心理健康状态。"
```

#### 干预策略

**即时干预**:
1. **高风险**: 立即提供紧急联系方式，建议寻求专业帮助
2. **中风险**: 提供心理支持资源，鼓励寻求专业咨询
3. **低风险**: 提供自助建议和预防性指导

**持续监护**:
```python
class CrisisMonitor:
    """危机监控系统"""
    
    def __init__(self):
        self.risk_history = {}
        self.alert_threshold = 3  # 连续风险检测阈值
    
    def track_user_risk(self, user_id: str, risk_level: str):
        """跟踪用户风险状态"""
        if user_id not in self.risk_history:
            self.risk_history[user_id] = []
        
        self.risk_history[user_id].append({
            'risk_level': risk_level,
            'timestamp': datetime.now()
        })
        
        # 保留最近10次记录
        self.risk_history[user_id] = self.risk_history[user_id][-10:]
        
        # 检查是否需要升级干预
        if self._should_escalate(user_id):
            self._escalate_intervention(user_id)
    
    def _should_escalate(self, user_id: str) -> bool:
        """判断是否需要升级干预"""
        recent_risks = self.risk_history.get(user_id, [])[-3:]
        return len([r for r in recent_risks if r['risk_level'] in ['high', 'medium']]) >= 2
    
    def _escalate_intervention(self, user_id: str):
        """升级干预措施"""
        # 发送警报给管理员
        # 自动联系紧急联系人
        # 记录到危机日志
        logger.critical(f"用户 {user_id} 需要紧急干预")
```

#### 质量保证
1. **准确性验证**: 定期评估关键词检测的准确率
2. **误报控制**: 平衡敏感性和特异性，减少误报
3. **响应时效**: 确保危机响应在秒级完成
4. **专业审核**: 定期由心理专家审核干预策略

### 8. 流式响应与性能优化

#### 流式服务模块

**文件位置**: `services/streaming_service.py`

**核心实现**:
```python
class StreamingService:
    """流式响应服务"""
    
    def __init__(self):
        self.client = OpenAI(
            api_key=get_config().deepseek.api_key,
            base_url="https://api.deepseek.com"
        )
    
    async def stream_chat_completion(self, messages: List[dict], 
                                   model: str = "deepseek-chat",
                                   temperature: float = 0.7) -> AsyncGenerator[str, None]:
        """流式聊天完成"""
        try:
            response = await self.client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                stream=True,
                max_tokens=2000
            )
            
            async for chunk in response:
                if chunk.choices[0].delta.content:
                    content = chunk.choices[0].delta.content
                    yield self._format_sse_data(content)
                    
        except Exception as e:
            yield self._format_sse_data(f"流式响应错误: {str(e)}")
    
    def _format_sse_data(self, data: str) -> str:
        """格式化SSE数据"""
        return f"data: {json.dumps({'content': data}, ensure_ascii=False)}\n\n"
    
    async def stream_psychological_chat(self, user_input: str, 
                                      chat_history: List[dict] = None) -> AsyncGenerator[str, None]:
        """心理咨询流式对话"""
        system_prompt = """
您是一位专业的心理咨询师，具有丰富的心理学知识和咨询经验。
请遵循以下原则：
1. 保持专业、温暖、非评判的态度
2. 运用共情技巧，理解和反映用户的情感
3. 提供专业的心理学见解和建议
4. 在必要时建议寻求专业帮助
5. 保护用户隐私和尊严
        """
        
        messages = [{"role": "system", "content": system_prompt}]
        
        if chat_history:
            messages.extend(chat_history)
        
        messages.append({"role": "user", "content": user_input})
        
        async for chunk in self.stream_chat_completion(messages):
            yield chunk
```

#### 性能优化策略

**1. 连接池管理**:
```python
class ConnectionPoolManager:
    """连接池管理器"""
    
    def __init__(self):
        self.pools = {
            'database': self._create_db_pool(),
            'redis': self._create_redis_pool(),
            'http': self._create_http_pool()
        }
    
    def _create_db_pool(self):
        """创建数据库连接池"""
        return create_engine(
            DATABASE_URL,
            pool_size=20,
            max_overflow=30,
            pool_pre_ping=True,
            pool_recycle=3600
        )
    
    def _create_redis_pool(self):
        """创建Redis连接池"""
        return redis.ConnectionPool(
            host=REDIS_HOST,
            port=REDIS_PORT,
            db=REDIS_DB,
            max_connections=50
        )
```

**2. 缓存策略**:
```python
class CacheManager:
    """缓存管理器"""
    
    def __init__(self):
        self.redis_client = redis.Redis(connection_pool=redis_pool)
        self.local_cache = {}
        self.cache_ttl = {
            'intent_analysis': 300,  # 5分钟
            'document_search': 600,  # 10分钟
            'user_profile': 1800,    # 30分钟
        }
    
    async def get_cached_intent(self, user_input: str) -> Optional[dict]:
        """获取缓存的意图分析结果"""
        cache_key = f"intent:{hashlib.md5(user_input.encode()).hexdigest()}"
        
        # 先检查本地缓存
        if cache_key in self.local_cache:
            return self.local_cache[cache_key]
        
        # 再检查Redis缓存
        cached_data = await self.redis_client.get(cache_key)
        if cached_data:
            result = json.loads(cached_data)
            self.local_cache[cache_key] = result
            return result
        
        return None
    
    async def cache_intent_result(self, user_input: str, result: dict):
        """缓存意图分析结果"""
        cache_key = f"intent:{hashlib.md5(user_input.encode()).hexdigest()}"
        ttl = self.cache_ttl['intent_analysis']
        
        # 存储到Redis
        await self.redis_client.setex(
            cache_key, 
            ttl, 
            json.dumps(result, ensure_ascii=False)
        )
        
        # 存储到本地缓存
        self.local_cache[cache_key] = result
```

**3. 异步处理优化**:
```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

class AsyncProcessor:
    """异步处理器"""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=10)
        self.semaphore = asyncio.Semaphore(5)  # 限制并发数
    
    async def process_with_timeout(self, coro, timeout: float = 30.0):
        """带超时的异步处理"""
        try:
            return await asyncio.wait_for(coro, timeout=timeout)
        except asyncio.TimeoutError:
            raise TimeoutError(f"处理超时（{timeout}秒）")
    
    async def parallel_process(self, tasks: List[Callable]) -> List[Any]:
        """并行处理多个任务"""
        async with self.semaphore:
            results = await asyncio.gather(*tasks, return_exceptions=True)
            return results
```

## 数据库设计

### 数据库架构

#### MySQL主数据库

**用户表 (users)**:
```sql
CREATE TABLE users (
    user_id VARCHAR(36) PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    email VARCHAR(100) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    last_login_at TIMESTAMP NULL,
    current_emotion VARCHAR(50) NULL,
    emotion_history JSON NULL,
    emotion_updated_at TIMESTAMP NULL,
    INDEX idx_email (email),
    INDEX idx_username (username),
    INDEX idx_active (is_active)
);
```

**会话表 (conversations)**:
```sql
CREATE TABLE conversations (
    conversation_id VARCHAR(36) PRIMARY KEY,
    user_id VARCHAR(36) NULL,
    title VARCHAR(200) NOT NULL DEFAULT '新对话',
    message_count INT DEFAULT 0,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
    last_message_at TIMESTAMP NULL,
    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE SET NULL,
    INDEX idx_user_id (user_id),
    INDEX idx_active (is_active),
    INDEX idx_last_message (last_message_at)
);
```

**消息表 (messages)**:
```sql
CREATE TABLE messages (
    message_id VARCHAR(36) PRIMARY KEY,
    conversation_id VARCHAR(36) NOT NULL,
    role ENUM('user', 'assistant') NOT NULL,
    content TEXT NOT NULL,
    model_name VARCHAR(100) NULL,
    temperature FLOAT NULL,
    message_metadata JSON NULL,
    feedback INT NULL CHECK (feedback IN (-1, 0, 1)),
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    FOREIGN KEY (conversation_id) REFERENCES conversations(conversation_id) ON DELETE CASCADE,
    INDEX idx_conversation_id (conversation_id),
    INDEX idx_role (role),
    INDEX idx_created_at (created_at),
    INDEX idx_feedback (feedback)
);
```

**危机记录表 (crisis_logs)**:
```sql
CREATE TABLE crisis_logs (
    log_id VARCHAR(36) PRIMARY KEY,
    user_id VARCHAR(36) NULL,
    conversation_id VARCHAR(36) NULL,
    risk_level ENUM('low', 'medium', 'high') NOT NULL,
    trigger_content TEXT NOT NULL,
    intervention_response TEXT NOT NULL,
    resolved BOOLEAN DEFAULT FALSE,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    resolved_at TIMESTAMP NULL,
    FOREIGN KEY (user_id) REFERENCES users(user_id) ON DELETE SET NULL,
    FOREIGN KEY (conversation_id) REFERENCES conversations(conversation_id) ON DELETE SET NULL,
    INDEX idx_user_id (user_id),
    INDEX idx_risk_level (risk_level),
    INDEX idx_resolved (resolved),
    INDEX idx_created_at (created_at)
);
```

#### Chroma向量数据库

**集合配置**:
```python
chroma_config = {
    "collection_name": "psychological_knowledge",
    "embedding_function": "text-embedding-ada-002",
    "distance_metric": "cosine",
    "metadata_fields": [
        "source",      # 文档来源
        "category",    # 分类（抑郁、焦虑、治疗方法等）
        "authority",   # 权威性评分
        "last_updated", # 最后更新时间
        "language"     # 语言
    ]
}
```

**文档结构**:
```json
{
    "id": "doc_001",
    "content": "抑郁症是一种常见的心理疾病...",
    "embedding": [0.1, 0.2, ...],
    "metadata": {
        "source": "DSM-5",
        "category": "抑郁症",
        "authority": 0.95,
        "last_updated": "2024-01-15",
        "language": "zh-CN"
    }
}
```

### 数据库优化策略

#### 索引优化
```sql
-- 复合索引优化查询性能
CREATE INDEX idx_user_conversations ON conversations(user_id, is_active, last_message_at);
CREATE INDEX idx_conversation_messages ON messages(conversation_id, created_at);
CREATE INDEX idx_crisis_monitoring ON crisis_logs(user_id, risk_level, created_at);

-- 全文索引支持内容搜索
CREATE FULLTEXT INDEX idx_message_content ON messages(content);
```

#### 分区策略
```sql
-- 按时间分区消息表
ALTER TABLE messages PARTITION BY RANGE (YEAR(created_at)) (
    PARTITION p2024 VALUES LESS THAN (2025),
    PARTITION p2025 VALUES LESS THAN (2026),
    PARTITION p_future VALUES LESS THAN MAXVALUE
);
```

#### 数据归档
```python
class DataArchiver:
    """数据归档器"""
    
    async def archive_old_conversations(self, days_old: int = 365):
        """归档旧会话数据"""
        cutoff_date = datetime.now() - timedelta(days=days_old)
        
        # 查找需要归档的会话
        old_conversations = await self.db.execute(
            select(Conversation)
            .where(Conversation.last_message_at < cutoff_date)
            .where(Conversation.is_active == False)
        )
        
        for conversation in old_conversations:
            # 导出到归档存储
            await self.export_to_archive(conversation)
            # 从主数据库删除
            await self.db.delete(conversation)
        
        await self.db.commit()
    
    async def export_to_archive(self, conversation: Conversation):
        """导出会话到归档存储"""
        archive_data = {
            'conversation': conversation.to_dict(),
            'messages': [msg.to_dict() for msg in conversation.messages],
            'archived_at': datetime.now().isoformat()
        }
        
        # 存储到对象存储（如AWS S3、阿里云OSS等）
        archive_key = f"archives/{conversation.conversation_id}.json"
        await self.object_storage.put(archive_key, json.dumps(archive_data))
```

## API接口设计

### RESTful API规范

#### 认证接口
```python
# POST /api/auth/register
{
    "username": "user123",
    "email": "user@example.com",
    "password": "SecurePass123!"
}

# Response
{
    "user_id": "uuid",
    "username": "user123",
    "email": "user@example.com",
    "access_token": "jwt_token",
    "refresh_token": "refresh_token",
    "token_type": "bearer",
    "expires_in": 1800
}

# POST /api/auth/login
{
    "email": "user@example.com",
    "password": "SecurePass123!"
}

# POST /api/auth/refresh
{
    "refresh_token": "refresh_token"
}

# POST /api/auth/logout
# Headers: Authorization: Bearer <access_token>
```

#### 会话管理接口
```python
# GET /api/conversations
# Headers: Authorization: Bearer <access_token>
# Response
{
    "conversations": [
        {
            "conversation_id": "uuid",
            "title": "关于焦虑的咨询",
            "message_count": 15,
            "last_message_at": "2024-01-15T10:30:00Z",
            "created_at": "2024-01-15T09:00:00Z"
        }
    ],
    "total": 10,
    "page": 1,
    "per_page": 20
}

# POST /api/conversations
{
    "title": "新的心理咨询"
}

# GET /api/conversations/{conversation_id}/messages
# Response
{
    "messages": [
        {
            "message_id": "uuid",
            "role": "user",
            "content": "我最近感到很焦虑",
            "created_at": "2024-01-15T10:00:00Z"
        },
        {
            "message_id": "uuid",
            "role": "assistant",
            "content": "我理解您的感受...",
            "created_at": "2024-01-15T10:01:00Z",
            "model_name": "deepseek-chat",
            "temperature": 0.7
        }
    ]
}

# DELETE /api/conversations/{conversation_id}
```

#### 聊天接口
```python
# POST /api/chat
{
    "message": "我最近总是失眠，该怎么办？",
    "conversation_id": "uuid",  # 可选
    "stream": true  # 是否流式响应
}

# 非流式响应
{
    "response": "失眠是一个常见的问题...",
    "conversation_id": "uuid",
    "message_id": "uuid",
    "intent": "consultation",
    "emotion": "concerned",
    "processing_time": 2.5
}

# 流式响应 (Server-Sent Events)
data: {"type": "start", "message": "正在分析您的问题..."}
data: {"type": "progress", "message": "正在搜索相关资料..."}
data: {"type": "content", "content": "失眠确实是一个"}
data: {"type": "content", "content": "常见的睡眠问题..."}
data: {"type": "end", "conversation_id": "uuid", "message_id": "uuid"}
```

#### 健康检查接口
```python
# GET /api/health
{
    "status": "healthy",
    "timestamp": "2024-01-15T10:00:00Z",
    "version": "1.0.0",
    "services": {
        "database": "connected",
        "vector_store": "connected",
        "llm_service": "available",
        "cache": "connected"
    }
}

# GET /api/metrics
{
    "active_users": 150,
    "total_conversations": 1250,
    "messages_today": 3500,
    "average_response_time": 2.3,
    "system_load": 0.65
}
```

### API安全与限流

#### 请求限流
```python
from slowapi import Limiter, _rate_limit_exceeded_handler
from slowapi.util import get_remote_address
from slowapi.errors import RateLimitExceeded

limiter = Limiter(key_func=get_remote_address)
app.state.limiter = limiter
app.add_exception_handler(RateLimitExceeded, _rate_limit_exceeded_handler)

@app.post("/api/chat")
@limiter.limit("10/minute")  # 每分钟最多10次请求
async def chat_endpoint(request: Request, chat_request: ChatRequest):
    """聊天接口"""
    pass

@app.post("/api/auth/login")
@limiter.limit("5/minute")  # 登录限制更严格
async def login_endpoint(request: Request, login_data: LoginRequest):
    """登录接口"""
    pass
```

#### 输入验证
```python
from pydantic import BaseModel, validator, Field
from typing import Optional

class ChatRequest(BaseModel):
    message: str = Field(..., min_length=1, max_length=2000)
    conversation_id: Optional[str] = Field(None, regex=r'^[0-9a-f-]{36}$')
    stream: bool = Field(default=False)
    
    @validator('message')
    def validate_message(cls, v):
        if not v.strip():
            raise ValueError('消息内容不能为空')
        return v.strip()

class RegisterRequest(BaseModel):
    username: str = Field(..., min_length=3, max_length=50, regex=r'^[a-zA-Z0-9_]+$')
    email: str = Field(..., regex=r'^[\w\.-]+@[\w\.-]+\.\w+$')
    password: str = Field(..., min_length=8, max_length=128)
    
    @validator('password')
    def validate_password(cls, v):
        if not any(c.isupper() for c in v):
            raise ValueError('密码必须包含至少一个大写字母')
        if not any(c.islower() for c in v):
            raise ValueError('密码必须包含至少一个小写字母')
        if not any(c.isdigit() for c in v):
            raise ValueError('密码必须包含至少一个数字')
        return v
```

## 部署与运维

### 容器化部署

#### Dockerfile
```dockerfile
FROM python:3.11-slim

# 设置工作目录
WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY pyproject.toml poetry.lock ./

# 安装Poetry
RUN pip install poetry

# 配置Poetry
RUN poetry config virtualenvs.create false

# 安装Python依赖
RUN poetry install --no-dev

# 复制应用代码
COPY . .

# 创建非root用户
RUN useradd -m -u 1000 appuser && chown -R appuser:appuser /app
USER appuser

# 暴露端口
EXPOSE 8000

# 健康检查
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/api/health || exit 1

# 启动命令
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
```

#### Docker Compose
```yaml
version: '3.8'

services:
  app:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=mysql+pymysql://user:password@db:3306/psychological_chat
      - REDIS_URL=redis://redis:6379/0
      - DEEPSEEK_API_KEY=${DEEPSEEK_API_KEY}
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - db
      - redis
    volumes:
      - ./chroma_db:/app/chroma_db
      - ./logs:/app/logs
    restart: unless-stopped
    
  db:
    image: mysql:8.0
    environment:
      - MYSQL_ROOT_PASSWORD=rootpassword
      - MYSQL_DATABASE=psychological_chat
      - MYSQL_USER=user
      - MYSQL_PASSWORD=password
    ports:
      - "3306:3306"
    volumes:
      - mysql_data:/var/lib/mysql
      - ./init.sql:/docker-entrypoint-initdb.d/init.sql
    restart: unless-stopped
    
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - app
    restart: unless-stopped

volumes:
  mysql_data:
  redis_data:
```

### 监控与日志

#### 日志配置
```python
import logging
from logging.handlers import RotatingFileHandler
import structlog

# 结构化日志配置
structlog.configure(
    processors=[
        structlog.stdlib.filter_by_level,
        structlog.stdlib.add_logger_name,
        structlog.stdlib.add_log_level,
        structlog.stdlib.PositionalArgumentsFormatter(),
        structlog.processors.TimeStamper(fmt="iso"),
        structlog.processors.StackInfoRenderer(),
        structlog.processors.format_exc_info,
        structlog.processors.UnicodeDecoder(),
        structlog.processors.JSONRenderer()
    ],
    context_class=dict,
    logger_factory=structlog.stdlib.LoggerFactory(),
    wrapper_class=structlog.stdlib.BoundLogger,
    cache_logger_on_first_use=True,
)

# 文件日志处理器
file_handler = RotatingFileHandler(
    'logs/app.log',
    maxBytes=10*1024*1024,  # 10MB
    backupCount=5
)
file_handler.setLevel(logging.INFO)

# 错误日志处理器
error_handler = RotatingFileHandler(
    'logs/error.log',
    maxBytes=10*1024*1024,
    backupCount=5
)
error_handler.setLevel(logging.ERROR)

# 配置根日志器
logging.basicConfig(
    level=logging.INFO,
    handlers=[file_handler, error_handler],
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = structlog.get_logger()
```

#### 性能监控
```python
from prometheus_client import Counter, Histogram, Gauge, generate_latest
import time

# 定义监控指标
REQUEST_COUNT = Counter('http_requests_total', 'Total HTTP requests', ['method', 'endpoint', 'status'])
REQUEST_DURATION = Histogram('http_request_duration_seconds', 'HTTP request duration')
ACTIVE_CONNECTIONS = Gauge('active_connections', 'Active WebSocket connections')
LLM_RESPONSE_TIME = Histogram('llm_response_time_seconds', 'LLM response time')
CRISIS_ALERTS = Counter('crisis_alerts_total', 'Total crisis alerts triggered')

# 中间件
@app.middleware("http")
async def monitor_requests(request: Request, call_next):
    start_time = time.time()
    
    response = await call_next(request)
    
    duration = time.time() - start_time
    REQUEST_DURATION.observe(duration)
    REQUEST_COUNT.labels(
        method=request.method,
        endpoint=request.url.path,
        status=response.status_code
    ).inc()
    
    return response

# 监控端点
@app.get("/metrics")
async def metrics():
    return Response(generate_latest(), media_type="text/plain")
```

### 安全配置

#### HTTPS配置
```nginx
server {
    listen 80;
    server_name your-domain.com;
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;
    
    ssl_certificate /etc/nginx/ssl/cert.pem;
    ssl_certificate_key /etc/nginx/ssl/key.pem;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    ssl_prefer_server_ciphers off;
    
    # 安全头
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=63072000; includeSubDomains; preload";
    
    location / {
        proxy_pass http://app:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket支持
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
    }
    
    # 静态文件缓存
    location /static/ {
        expires 1y;
        add_header Cache-Control "public, immutable";
    }
}
```

#### 环境变量管理
```bash
# .env.production
DATABASE_URL=mysql+pymysql://user:password@db:3306/psychological_chat
REDIS_URL=redis://redis:6379/0
DEEPSEEK_API_KEY=your_deepseek_api_key
OPENAI_API_KEY=your_openai_api_key
SECRET_KEY=your_secret_key_here
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
REFRESH_TOKEN_EXPIRE_DAYS=7
ENVIRONMENT=production
LOG_LEVEL=INFO
CORS_ORIGINS=https://your-frontend-domain.com
MAX_UPLOAD_SIZE=10485760  # 10MB
RATE_LIMIT_PER_MINUTE=60
```

## 测试策略

### 单元测试

```python
import pytest
from fastapi.testclient import TestClient
from unittest.mock import Mock, patch
from main import app
from core.psychological_tools import analyze_intent, check_safety

client = TestClient(app)

class TestPsychologicalTools:
    """心理工具测试类"""
    
    def test_analyze_intent_crisis(self):
        """测试危机意图识别"""
        user_input = "我不想活了，想要自杀"
        result = analyze_intent(user_input)
        
        import json
        parsed_result = json.loads(result)
        
        assert parsed_result["intent"] == "crisis"
        assert parsed_result["confidence"] >= 0.8
        assert parsed_result["urgency"] == "high"
    
    def test_analyze_intent_consultation(self):
        """测试咨询意图识别"""
        user_input = "我最近感到很抑郁，需要心理咨询"
        result = analyze_intent(user_input)
        
        import json
        parsed_result = json.loads(result)
        
        assert parsed_result["intent"] == "consultation"
        assert parsed_result["confidence"] >= 0.7
    
    def test_check_safety_high_risk(self):
        """测试高风险安全检查"""
        user_input = "我想死，准备跳楼自杀"
        result = check_safety(user_input)
        
        import json
        parsed_result = json.loads(result)
        
        assert parsed_result["risk_level"] == "high"
        assert "紧急求助热线" in parsed_result["response"]
    
    def test_check_safety_safe(self):
        """测试安全输入"""
        user_input = "今天天气很好"
        result = check_safety(user_input)
        
        import json
        parsed_result = json.loads(result)
        
        assert parsed_result["risk_level"] == "safe"

class TestAPI:
    """API接口测试类"""
    
    def test_health_check(self):
        """测试健康检查接口"""
        response = client.get("/api/health")
        assert response.status_code == 200
        assert response.json()["status"] == "healthy"
    
    @patch('core.psychological_controller.PsychologicalChatController')
    def test_chat_endpoint(self, mock_controller):
        """测试聊天接口"""
        mock_controller.return_value.process_message_stream.return_value = [
            {"type": "content", "content": "测试响应"}
        ]
        
        response = client.post("/api/chat", json={
            "message": "你好",
            "stream": False
        })
        
        assert response.status_code == 200
    
    def test_register_user(self):
        """测试用户注册"""
        response = client.post("/api/auth/register", json={
            "username": "testuser",
            "email": "test@example.com",
            "password": "TestPass123!"
        })
        
        assert response.status_code in [200, 201, 409]  # 409表示用户已存在

@pytest.fixture
def mock_vector_store():
    """模拟向量存储"""
    with patch('core.vector_store.get_vector_store') as mock:
        mock_store = Mock()
        mock_store.similarity_search.return_value = [
            Mock(page_content="测试文档内容1"),
            Mock(page_content="测试文档内容2")
        ]
        mock.return_value = mock_store
        yield mock_store

@pytest.fixture
def mock_llm():
    """模拟大语言模型"""
    with patch('core.llm.get_llm') as mock:
        mock_llm = Mock()
        mock_llm.invoke.return_value = Mock(content="测试LLM响应")
        mock.return_value = mock_llm
        yield mock_llm
```

### 集成测试

```python
import pytest
import asyncio
from httpx import AsyncClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from models.base import Base
from database import get_db
from main import app

# 测试数据库配置
TEST_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(TEST_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

def override_get_db():
    try:
        db = TestingSessionLocal()
        yield db
    finally:
        db.close()

app.dependency_overrides[get_db] = override_get_db

@pytest.fixture(scope="session")
def setup_test_db():
    """设置测试数据库"""
    Base.metadata.create_all(bind=engine)
    yield
    Base.metadata.drop_all(bind=engine)

@pytest.mark.asyncio
class TestIntegration:
    """集成测试类"""
    
    async def test_complete_chat_flow(self, setup_test_db):
        """测试完整的聊天流程"""
        async with AsyncClient(app=app, base_url="http://test") as ac:
            # 1. 注册用户
            register_response = await ac.post("/api/auth/register", json={
                "username": "testuser",
                "email": "test@example.com",
                "password": "TestPass123!"
            })
            
            if register_response.status_code == 201:
                user_data = register_response.json()
                token = user_data["access_token"]
            else:
                # 用户已存在，尝试登录
                login_response = await ac.post("/api/auth/login", json={
                    "email": "test@example.com",
                    "password": "TestPass123!"
                })
                assert login_response.status_code == 200
                token = login_response.json()["access_token"]
            
            headers = {"Authorization": f"Bearer {token}"}
            
            # 2. 创建会话
            conversation_response = await ac.post(
                "/api/conversations",
                json={"title": "测试会话"},
                headers=headers
            )
            assert conversation_response.status_code == 201
            conversation_id = conversation_response.json()["conversation_id"]
            
            # 3. 发送消息
            chat_response = await ac.post("/api/chat", json={
                "message": "我感到很焦虑",
                "conversation_id": conversation_id,
                "stream": False
            }, headers=headers)
            
            assert chat_response.status_code == 200
            chat_data = chat_response.json()
            assert "response" in chat_data
            assert chat_data["conversation_id"] == conversation_id
            
            # 4. 获取会话历史
            messages_response = await ac.get(
                f"/api/conversations/{conversation_id}/messages",
                headers=headers
            )
            assert messages_response.status_code == 200
            messages = messages_response.json()["messages"]
            assert len(messages) >= 2  # 用户消息 + 助手回复
```

### 性能测试

```python
import asyncio
import aiohttp
import time
from concurrent.futures import ThreadPoolExecutor

class PerformanceTest:
    """性能测试类"""
    
    def __init__(self, base_url: str = "http://localhost:8000"):
        self.base_url = base_url
        self.results = []
    
    async def single_request(self, session: aiohttp.ClientSession, endpoint: str, data: dict = None):
        """单个请求测试"""
        start_time = time.time()
        
        try:
            if data:
                async with session.post(f"{self.base_url}{endpoint}", json=data) as response:
                    await response.text()
                    status = response.status
            else:
                async with session.get(f"{self.base_url}{endpoint}") as response:
                    await response.text()
                    status = response.status
            
            duration = time.time() - start_time
            self.results.append({
                'endpoint': endpoint,
                'duration': duration,
                'status': status,
                'success': status == 200
            })
            
        except Exception as e:
            duration = time.time() - start_time
            self.results.append({
                'endpoint': endpoint,
                'duration': duration,
                'status': 0,
                'success': False,
                'error': str(e)
            })
    
    async def load_test(self, endpoint: str, concurrent_users: int = 10, 
                       requests_per_user: int = 10, data: dict = None):
        """负载测试"""
        connector = aiohttp.TCPConnector(limit=100)
        async with aiohttp.ClientSession(connector=connector) as session:
            tasks = []
            
            for _ in range(concurrent_users):
                for _ in range(requests_per_user):
                    task = self.single_request(session, endpoint, data)
                    tasks.append(task)
            
            await asyncio.gather(*tasks)
    
    def analyze_results(self):
        """分析测试结果"""
        if not self.results:
            return {}
        
        successful_requests = [r for r in self.results if r['success']]
        failed_requests = [r for r in self.results if not r['success']]
        
        if successful_requests:
            durations = [r['duration'] for r in successful_requests]
            avg_duration = sum(durations) / len(durations)
            max_duration = max(durations)
            min_duration = min(durations)
            
            # 计算百分位数
            sorted_durations = sorted(durations)
            p95_index = int(len(sorted_durations) * 0.95)
            p99_index = int(len(sorted_durations) * 0.99)
            
            return {
                'total_requests': len(self.results),
                'successful_requests': len(successful_requests),
                'failed_requests': len(failed_requests),
                'success_rate': len(successful_requests) / len(self.results) * 100,
                'average_response_time': avg_duration,
                'max_response_time': max_duration,
                'min_response_time': min_duration,
                'p95_response_time': sorted_durations[p95_index] if p95_index < len(sorted_durations) else max_duration,
                'p99_response_time': sorted_durations[p99_index] if p99_index < len(sorted_durations) else max_duration,
                'requests_per_second': len(successful_requests) / sum(durations) if sum(durations) > 0 else 0
            }
        
        return {
            'total_requests': len(self.results),
            'successful_requests': 0,
            'failed_requests': len(failed_requests),
            'success_rate': 0
        }

# 运行性能测试
async def run_performance_tests():
    """运行性能测试"""
    test = PerformanceTest()
    
    # 测试健康检查接口
    print("测试健康检查接口...")
    await test.load_test("/api/health", concurrent_users=20, requests_per_user=50)
    health_results = test.analyze_results()
    print(f"健康检查接口测试结果: {health_results}")
    
    # 重置结果
    test.results = []
    
    # 测试聊天接口
    print("测试聊天接口...")
    chat_data = {"message": "你好", "stream": False}
    await test.load_test("/api/chat", concurrent_users=10, requests_per_user=20, data=chat_data)
    chat_results = test.analyze_results()
    print(f"聊天接口测试结果: {chat_results}")

if __name__ == "__main__":
    asyncio.run(run_performance_tests())
```

## 未来发展规划

### 短期目标（1-3个月）

1. **完善核心功能**
   - 实现BM25关键词搜索算法
   - 完善混合搜索结果融合策略
   - 优化文档处理流水线，支持更多文件格式
   - 增强危机识别算法的准确性

2. **性能优化**
   - 集成Redis缓存系统
   - 实现数据库连接池优化
   - 添加CDN支持静态资源加速
   - 优化向量检索性能

3. **用户体验提升**
   - 实现实时打字指示器
   - 添加消息状态显示（发送中、已送达、已读）
   - 支持消息编辑和删除功能
   - 实现会话导出功能

### 中期目标（3-6个月）

1. **智能化增强**
   - 集成情感分析模型，实时监测用户情绪变化
   - 实现个性化推荐系统，根据用户历史提供定制化建议
   - 添加多轮对话上下文理解能力
   - 实现智能话题引导和转换

2. **专业化功能**
   - 集成标准化心理评估量表（PHQ-9、GAD-7等）
   - 实现心理健康报告生成
   - 添加专业术语解释和科普功能
   - 支持多种心理治疗方法（CBT、DBT等）

3. **多模态支持**
   - 支持语音输入和输出
   - 添加图片和文档上传功能
   - 实现视频通话预约功能
   - 支持表情符号和贴纸

### 长期目标（6-12个月）

1. **平台化发展**
   - 开发移动端应用（iOS/Android）
   - 实现多租户架构，支持机构部署
   - 添加管理后台和数据分析面板
   - 支持第三方集成和API开放

2. **AI能力升级**
   - 训练专门的心理健康领域模型
   - 实现多语言支持（英语、日语等）
   - 添加预测性分析，提前识别心理健康风险
   - 集成最新的大语言模型技术

3. **生态系统建设**
   - 建立专业心理咨询师网络
   - 实现在线预约和支付系统
   - 添加社区功能，支持用户互助
   - 建立心理健康知识库和资源中心

### 技术债务清理

1. **代码质量提升**
   - 增加单元测试覆盖率至90%以上
   - 实现自动化代码审查和质量检查
   - 重构遗留代码，提高可维护性
   - 建立完善的文档体系

2. **安全性加强**
   - 实现端到端加密
   - 添加数据脱敏和匿名化功能
   - 完善访问控制和权限管理
   - 通过安全认证（如ISO 27001）

3. **可扩展性优化**
   - 实现微服务架构拆分
   - 添加服务网格和API网关
   - 支持容器编排和自动扩缩容
   - 实现多区域部署和灾备

### 商业化考虑

1. **盈利模式**
   - 免费基础版 + 付费高级功能
   - 企业版本和定制化服务
   - 专业咨询师平台抽成
   - 数据洞察和报告服务

2. **合规要求**
   - 医疗器械认证申请
   - 数据保护法规遵循（GDPR、CCPA等）
   - 心理健康行业标准认证
   - 隐私政策和用户协议完善

3. **市场推广**
   - 与医疗机构和学校合作
   - 参与心理健康公益活动
   - 建立品牌知名度和用户信任
   - 收集用户反馈和改进建议

## 总结

心理健康聊天机器人后端系统是一个复杂而重要的项目，它结合了先进的AI技术、严格的安全标准和专业的心理学知识。通过模块化的设计、完善的测试策略和持续的优化改进，系统能够为用户提供安全、专业、个性化的心理健康服务。

### 核心优势

1. **技术先进性**: 采用最新的大语言模型和向量检索技术
2. **安全可靠性**: 完善的危机识别和干预机制
3. **专业性**: 基于心理学专业知识的对话设计
4. **可扩展性**: 模块化架构支持功能快速迭代
5. **用户体验**: 流式响应和个性化服务

### 关键挑战

1. **准确性**: 确保AI回复的专业性和准确性
2. **安全性**: 有效识别和处理心理危机情况
3. **隐私保护**: 严格保护用户敏感信息
4. **性能优化**: 在高并发下保持响应速度
5. **持续改进**: 基于用户反馈不断优化系统

通过持续的技术创新和专业化发展，这个系统有望成为心理健康领域的重要工具，为更多需要帮助的人提供及时、专业的心理支持服务。