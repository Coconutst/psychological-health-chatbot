"""å¿ƒç†å’¨è¯¢APIç«¯ç‚¹ - åŸºäºLangChain Toolsæ¶æ„"""

import asyncio
import json
import requests
import traceback
from typing import Dict, Any, Optional
from datetime import datetime

from fastapi import APIRouter, HTTPException, Depends
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from sqlalchemy.orm import Session

# å¯¼å…¥æ ¸å¿ƒæ¨¡å—
from app.core.tools.psychological_controller import psychological_controller
from app.core.memory.memory_manager import get_session_history, get_session_history_database, get_conversation_buffer_memory, _buffer_memories
from app.configs.database import get_db
from app.services.conversation_service import ConversationService
from app.services.streaming_service import StreamingService
from app.api.endpoints.auth import get_current_user_optional, get_current_user
from app.models.user import User
from app.configs.settings import api_settings
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºAPIè·¯ç”±å™¨
router = APIRouter()

# è¯·æ±‚æ¨¡å‹
class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    message: str = Field(..., description="ç”¨æˆ·æ¶ˆæ¯")  
    conversation_id: Optional[str] = Field(None, description="ä¼šè¯ID")
    model: str = Field("deepseek-chat", description="æ¨¡å‹åç§°")
    stream: bool = Field(True, description="æ˜¯å¦æµå¼å“åº”")

# éæµå¼å“åº”å¤„ç†å‡½æ•°
async def handle_non_stream_response(
    request: ChatRequest,
    db: Session,
    current_user: Optional[Any],
    conversation_id: str
) -> Dict[str, Any]:
    """å¤„ç†éæµå¼å“åº”"""
    try:
        logger.info(f"[API] å¤„ç†éæµå¼å“åº”ï¼Œä¼šè¯ID: {conversation_id}")
        
        # ä½¿ç”¨ConversationBufferMemoryè·å–åŒ…å«å†å²ä¸Šä¸‹æ–‡çš„å¯¹è¯è®°å¿†
        user_id = getattr(current_user, 'user_id', None) if current_user and not getattr(current_user, 'is_anonymous', False) else None
        
        # è·å–ConversationBufferMemoryï¼ˆè‡ªåŠ¨åŠ è½½å†å²ä¸Šä¸‹æ–‡ï¼‰
        buffer_memory = get_conversation_buffer_memory(
            session_id=conversation_id, 
            user_id=user_id, 
            load_historical_context=True
        )
        
        # ä»ConversationBufferMemoryè·å–æ ¼å¼åŒ–çš„å¯¹è¯å†å²
        memory_variables = buffer_memory.load_memory_variables({})
        chat_history = memory_variables.get('chat_history', [])
        
        # å°†LangChainæ¶ˆæ¯æ ¼å¼è½¬æ¢ä¸ºAPIæ ¼å¼
        formatted_history = []
        for message in chat_history:
            if hasattr(message, 'type'):
                role = "human" if message.type == "human" else "assistant"
            else:
                role = "human" if message.__class__.__name__ == "HumanMessage" else "assistant"
            
            formatted_history.append({
                "role": role,
                "content": message.content
            })
        
        logger.info(f"[API] ConversationBufferMemoryåŠ è½½äº† {len(formatted_history)} æ¡æ¶ˆæ¯ï¼ˆåŒ…å«å†å²ä¸Šä¸‹æ–‡ï¼‰")
        
        # æ·»åŠ å†…ç½®ç³»ç»Ÿè§’è‰²
        messages = [
            {
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¿ƒç†å¥åº·å’¨è¯¢å¸ˆAIåŠ©æ‰‹ã€‚ä½ å…·å¤‡ä¸°å¯Œçš„å¿ƒç†å­¦çŸ¥è¯†å’Œå’¨è¯¢ç»éªŒï¼Œèƒ½å¤Ÿä¸ºç”¨æˆ·æä¾›ä¸“ä¸šã€æ¸©æš–ã€æœ‰æ•ˆçš„å¿ƒç†æ”¯æŒå’Œå»ºè®®ã€‚è¯·ä»¥åŒç†å¿ƒã€ä¸“ä¸šæ€§å’Œå…³æ€€çš„æ€åº¦å›åº”ç”¨æˆ·çš„é—®é¢˜ã€‚"
            }
        ]
        
        # æ·»åŠ å†å²å¯¹è¯
        messages.extend(formatted_history)
        
        # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
        messages.append({
            "role": "user",
            "content": request.message
        })
        
        # ä½¿ç”¨å¿ƒç†å’¨è¯¢æ§åˆ¶å™¨å¤„ç†æ¶ˆæ¯ï¼ˆformatted_historyå·²åŒ…å«å†å²ä¸Šä¸‹æ–‡ï¼‰
        result = await psychological_controller.process_message(
            user_input=request.message,
            chat_history=formatted_history,
            timeout=30
        )
        
        # è·å–å“åº”å†…å®¹
        response_content = result.get("response")
        if not response_content:
            raise ValueError("No response generated from controller")
        
        # ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“ï¼ˆå¦‚æœç”¨æˆ·å·²ç™»å½•ï¼‰
        if current_user and hasattr(current_user, 'user_id') and not getattr(current_user, 'is_anonymous', False):
            try:
                conversation_service = ConversationService(db)
                
                # ç¡®ä¿å¯¹è¯è®°å½•å­˜åœ¨
                conversation = conversation_service.get_conversation(conversation_id)
                if not conversation:
                    conversation = conversation_service.create_conversation(
                        conversation_id=conversation_id,
                        user_id=str(current_user.user_id),
                        title=request.message[:30] + ('...' if len(request.message) > 30 else '')
                    )
                
                # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯å’ŒAIå›å¤
                conversation_service.add_message(
                    conversation_id=conversation_id,
                    role="human",
                    content=request.message
                )
                conversation_service.add_message(
                    conversation_id=conversation_id,
                    role="assistant",
                    content=response_content,
                    metadata=result.get("metadata", {})
                )
                
                # æ›´æ–°ConversationBufferMemoryç¼“å­˜
                try:
                    cache_key = f"{conversation_id}_{current_user.user_id or 'anonymous'}"
                    if cache_key in _buffer_memories:
                        buffer_memory = _buffer_memories[cache_key]
                        buffer_memory.chat_memory.add_user_message(request.message)
                        buffer_memory.chat_memory.add_ai_message(result["output"])
                        logger.debug(f"[NonStream] ConversationBufferMemoryç¼“å­˜å·²æ›´æ–°")
                except Exception as e:
                    logger.error(f"[NonStream] æ›´æ–°ConversationBufferMemoryç¼“å­˜å¤±è´¥: {e}")
                
                # æ›´æ–°ç”¨æˆ·æƒ…ç»ªç”»åƒ
                emotion = result.get("emotion")
                if emotion and emotion != "unknown":
                    conversation_service.update_user_emotion_profile(
                        user_id=str(current_user.user_id),
                        emotion=emotion,
                        confidence=result.get("confidence", 0.5),
                        emotion_context={
                            "conversation_id": conversation_id,
                            "message_content": request.message[:100]
                        }
                    )
                    
            except Exception as e:
                logger.error(f"[API] ä¿å­˜å¯¹è¯å¤±è´¥: {e}")
        
        # è¿”å›ç±»ä¼¼ DeepSeek API çš„å“åº”æ ¼å¼
        return {
            "id": f"chatcmpl-{conversation_id}",
            "object": "chat.completion",
            "created": int(datetime.now().timestamp()),
            "model": request.model,
            "choices": [
                {
                    "index": 0,
                    "message": {
                        "role": "assistant",
                        "content": response_content
                    },
                    "finish_reason": "stop"
                }
            ],
            "usage": {
                "prompt_tokens": len(request.message.split()),
                "completion_tokens": len(response_content.split()),
                "total_tokens": len(request.message.split()) + len(response_content.split())
            },
            "system_fingerprint": "psychological-health-chatbot",
            "metadata": {
                "conversation_id": conversation_id,
                "intent": result.get("intent", "unknown"),
                "emotion": result.get("emotion", "neutral"),
                "confidence": result.get("confidence", 0.5),
                "execution_time": result.get("execution_time", 0)
            }
        }
        
    except Exception as e:
        logger.error(f"[API] éæµå¼å“åº”å¤„ç†å¼‚å¸¸: {e}")
        raise HTTPException(
            status_code=500,
            detail=f"å¤„ç†è¯·æ±‚å¤±è´¥: {str(e)}"
        )

class SystemStatusResponse(BaseModel):
    """ç³»ç»ŸçŠ¶æ€å“åº”æ¨¡å‹"""
    tools_active: bool = Field(True, description="LangChain ToolsçŠ¶æ€")
    controller_active: bool = Field(True, description="å¿ƒç†å’¨è¯¢æ§åˆ¶å™¨çŠ¶æ€")
    database_active: bool = Field(True, description="æ•°æ®åº“çŠ¶æ€")
    vector_store_active: bool = Field(True, description="å‘é‡å­˜å‚¨çŠ¶æ€")
    system_status: str = Field("healthy", description="ç³»ç»ŸçŠ¶æ€")

class AnalysisResponse(BaseModel):
    """æ¶ˆæ¯åˆ†æå“åº”æ¨¡å‹"""
    intent: str = Field(..., description="æ„å›¾è¯†åˆ«")
    confidence: float = Field(..., description="ç½®ä¿¡åº¦")
    explanation: str = Field(..., description="åˆ†æè¯´æ˜")
    crisis_level: str = Field(..., description="å±æœºç­‰çº§")
    crisis_confidence: float = Field(..., description="å±æœºæ£€æµ‹ç½®ä¿¡åº¦")
    crisis_explanation: str = Field(..., description="å±æœºåˆ†æè¯´æ˜")
    requires_intervention: bool = Field(..., description="æ˜¯å¦éœ€è¦å¹²é¢„")
    timestamp: str = Field(..., description="æ—¶é—´æˆ³")

@router.post("/chat")
async def psychological_chat(
    request: ChatRequest,
    db: Session = Depends(get_db),
    current_user: Optional[Any] = Depends(get_current_user_optional)
):
    """å¿ƒç†å’¨è¯¢èŠå¤©æ¥å£ - åŸºäºLangChain Toolsï¼Œæ”¯æŒæµå¼å’Œéæµå¼å“åº”"""
    
    logger.info(f"[API] æ”¶åˆ°èŠå¤©è¯·æ±‚: {request.message[:50]}...")
    logger.info(f"[API] è¯·æ±‚å‚æ•° - model: {request.model}, stream: {request.stream}")
    
    # ç”Ÿæˆä¼šè¯ID
    user_id = getattr(current_user, 'user_id', 'anonymous')
    conversation_id = request.conversation_id or f"user_{user_id}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
    
    # å¦‚æœä¸æ˜¯æµå¼å“åº”ï¼Œç›´æ¥å¤„ç†å¹¶è¿”å›JSON
    if not request.stream:
        return await handle_non_stream_response(request, db, current_user, conversation_id)
    
    async def generate_stream():
        try:
            logger.info(f"[API] å¼€å§‹æµå¼å“åº”ç”Ÿæˆï¼Œä¼šè¯ID: {conversation_id}")
            
            # å‘é€å¤„ç†çŠ¶æ€
            yield f"data: {{\"type\": \"status\", \"message\": \"Processing your message...\"}}"
            
            # ä½¿ç”¨åŸºäºLangChain Toolsçš„å¿ƒç†å’¨è¯¢æ§åˆ¶å™¨
            logger.info(f"[API] å¼€å§‹å¿ƒç†å’¨è¯¢æ§åˆ¶å™¨å¤„ç†")
            
            response_content = ""
            error_occurred = False
            emotion = "unknown"
            confidence = 0.5
            execution_time = 0
            success = True
            result = {}
            
            try:
                # ä½¿ç”¨ConversationBufferMemoryè·å–åŒ…å«å†å²ä¸Šä¸‹æ–‡çš„å¯¹è¯è®°å¿†
                user_id = getattr(current_user, 'user_id', None) if current_user and not getattr(current_user, 'is_anonymous', False) else None
                
                # è·å–ConversationBufferMemoryï¼ˆè‡ªåŠ¨åŠ è½½å†å²ä¸Šä¸‹æ–‡ï¼‰
                buffer_memory = get_conversation_buffer_memory(
                    session_id=conversation_id, 
                    user_id=user_id, 
                    load_historical_context=True
                )
                
                # ä»ConversationBufferMemoryè·å–æ ¼å¼åŒ–çš„å¯¹è¯å†å²
                memory_variables = buffer_memory.load_memory_variables({})
                chat_history = memory_variables.get('chat_history', [])
                
                # å°†LangChainæ¶ˆæ¯æ ¼å¼è½¬æ¢ä¸ºAPIæ ¼å¼
                formatted_history = []
                for message in chat_history:
                    if hasattr(message, 'type'):
                        role = "human" if message.type == "human" else "assistant"
                    else:
                        role = "human" if message.__class__.__name__ == "HumanMessage" else "assistant"
                    
                    formatted_history.append({
                        "role": role,
                        "content": message.content
                    })
                
                logger.info(f"[Tools] ConversationBufferMemoryåŠ è½½äº† {len(formatted_history)} æ¡æ¶ˆæ¯ï¼ˆåŒ…å«å†å²ä¸Šä¸‹æ–‡ï¼‰")
                
                # å‘é€å·¥å…·å¤„ç†çŠ¶æ€
                tools_status = {
                    "type": "tools_status",
                    "message": "å¯åŠ¨LangChain Toolså¤„ç†æµç¨‹...",
                    "tools": ["æ„å›¾åˆ†æ", "å®‰å…¨æ£€æŸ¥", "æ–‡æ¡£æ£€ç´¢", "æ–‡æ¡£é‡æ’åº", "ç­”æ¡ˆç”Ÿæˆ"],
                    "status": "processing"
                }
                yield f"data: {json.dumps(tools_status, ensure_ascii=False)}"
                
                # ä½¿ç”¨åŸºäºLangChain Toolsçš„æ§åˆ¶å™¨å¤„ç†æ¶ˆæ¯
                logger.info(f"[Tools] ä½¿ç”¨Toolsæ§åˆ¶å™¨å¤„ç†æ¶ˆæ¯: {request.message[:50]}...")
                
                result = await psychological_controller.process_message(
                    user_input=request.message,
                    chat_history=formatted_history,  # formatted_historyå·²åŒ…å«å†å²ä¸Šä¸‹æ–‡
                    timeout=30
                )
                logger.info(f"[Tools] Toolsæ§åˆ¶å™¨æ‰§è¡Œå®Œæˆ")
                
                # è®°å½•è¯¦ç»†çš„æ‰§è¡Œç»“æœ
                logger.info(f"[MultiAgent] æ‰§è¡Œç»“æœè¯¦æƒ…:")
                logger.info(f"  - æ„å›¾: {result.get('intent', 'unknown')}")
                logger.info(f"  - ç½®ä¿¡åº¦: {result.get('confidence', 0)}")
                logger.info(f"  - æƒ…ç»ª: {result.get('emotion', 'unknown')}")
                logger.info(f"  - å±æœºç­‰çº§: {result.get('crisis_level', 'unknown')}")
                logger.info(f"  - å®‰å…¨è§¦å‘: {result.get('safety_triggered', False)}")
                logger.info(f"  - æ£€ç´¢æ–‡æ¡£æ•°: {result.get('documents_count', 0)}")
                logger.info(f"  - é‡æ’åºæ–‡æ¡£æ•°: {result.get('documents_count', 0)}")
                logger.info(f"  - æ‰§è¡Œæ—¶é—´: {result.get('execution_time', 0):.2f}ç§’")
                
                # è·å–å“åº”å†…å®¹å’Œå…ƒæ•°æ®
                response_content = result.get("response")
                if not response_content:
                    raise ValueError("No response generated from controller")
                emotion = result.get("emotion", "unknown")
                confidence = result.get("confidence", 0.5)
                execution_time = result.get("execution_time", 0)
                success = not result.get("error")
                
                logger.info(f"[MultiAgent] æœ€ç»ˆå“åº”é•¿åº¦: {len(response_content)} å­—ç¬¦")
                logger.info(f"[MultiAgent] æ‰§è¡ŒæˆåŠŸ: {success}")
                
                # å‘é€æ€è€ƒè¿‡ç¨‹
                thinking_steps = [
                    "ğŸ¤” æ­£åœ¨åˆ†ææ‚¨çš„é—®é¢˜...",
                    "ğŸ“š æ£€ç´¢ç›¸å…³çš„å¿ƒç†å¥åº·çŸ¥è¯†...",
                    "ğŸ§  æ•´åˆä¿¡æ¯å¹¶ç»„ç»‡å›å¤...",
                    "ğŸ’¡ å‡†å¤‡ä¸ºæ‚¨æä¾›ä¸“ä¸šå»ºè®®..."
                ]
                
                for step in thinking_steps:
                    thinking_data = {
                        "type": "thinking",
                        "content": step,
                        "conversation_id": conversation_id,
                        "timestamp": datetime.now().isoformat()
                    }
                    yield f"data: {json.dumps(thinking_data, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.5)  # æ€è€ƒè¿‡ç¨‹ç¨æ…¢ä¸€äº›
                
                # å‘é€å›å¤å¼€å§‹æ ‡è®°
                start_response_data = {
                    "type": "response_start",
                    "message": "ğŸ’¬ AIå¿ƒç†åŠ©æ‰‹å›å¤ï¼š",
                    "conversation_id": conversation_id,
                    "metadata": {
                        "intent": result.get("intent", "unknown"),
                        "emotion": result.get("emotion", "neutral"),
                        "confidence": result.get("confidence", 0.5),
                        "documents_used": result.get("retrieved_docs_count", 0),
                        "processing_time": f"{result.get('execution_time', 0):.2f}ç§’"
                    },
                    "timestamp": datetime.now().isoformat()
                }
                yield f"data: {json.dumps(start_response_data, ensure_ascii=False)}\n\n"
                
                # æµå¼è¿”å›å“åº”å†…å®¹ï¼ˆç¾åŒ–æ ¼å¼ï¼‰
                formatted_response = f"\n{response_content}\n\n---\n\nğŸ“Š **åˆ†æç»“æœ**\n" \
                                   f"â€¢ æ„å›¾è¯†åˆ«: {result.get('intent', 'unknown')}\n" \
                                   f"â€¢ æƒ…ç»ªçŠ¶æ€: {result.get('emotion', 'neutral')}\n" \
                                   f"â€¢ ç½®ä¿¡åº¦: {result.get('confidence', 0.5):.1%}\n" \
                                   f"â€¢ å‚è€ƒæ–‡æ¡£: {result.get('documents_count', 0)}ç¯‡\n" \
                                   f"â€¢ å¤„ç†æ—¶é—´: {result.get('execution_time', 0):.2f}ç§’"
                
                for char in formatted_response:
                    char_data = {
                        "type": "content",
                        "content": char,
                        "conversation_id": conversation_id,
                        "timestamp": datetime.now().isoformat()
                    }
                    yield f"data: {json.dumps(char_data, ensure_ascii=False)}\n\n"
                    await asyncio.sleep(0.01)
                    
            except Exception as e:
                logger.error(f"[MultiAgent] å¿ƒç†å’¨è¯¢æ§åˆ¶å™¨è°ƒç”¨é”™è¯¯: {e}")
                import traceback
                logger.error(f"[MultiAgent] å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                # ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä¸ä½¿ç”¨å¤‡ç”¨å“åº”
                raise
                
            # è®¾ç½®é»˜è®¤çš„å…ƒæ•°æ®å€¼ï¼ˆå¦‚æœæ²¡æœ‰ä»æ§åˆ¶å™¨è·å–åˆ°ï¼‰
            if 'emotion' not in locals():
                emotion = "unknown"
            if 'confidence' not in locals():
                confidence = 0.5
            if 'execution_time' not in locals():
                execution_time = 0
            if 'success' not in locals():
                success = True
            
            # æ£€æŸ¥å“åº”å†…å®¹æ˜¯å¦ç”ŸæˆæˆåŠŸ
            if 'response_content' not in locals() or not response_content:
                raise ValueError("Failed to generate response")
            
            result = {
                "output": response_content,
                "metadata": {
                    "multi_agent": True,
                    "emotion": emotion,
                    "confidence": confidence,
                    "execution_time": execution_time,
                    "success": success,
                    "agent_details": {
                        "intent": locals().get('result', {}).get('intent'),
                        "crisis_level": locals().get('result', {}).get('crisis_level'),
                        "safety_triggered": locals().get('result', {}).get('safety_triggered', False),
                        "retrieved_docs_count": locals().get('result', {}).get('documents_count', 0),
                        "reranked_docs_count": locals().get('result', {}).get('documents_count', 0),
                        "supervisor_completed": locals().get('result', {}).get('supervisor_completed', False),
                        "safety_completed": locals().get('result', {}).get('safety_completed', False)
                    }
                }
            }
            
            logger.info(f"[MultiAgent] å‡†å¤‡ä¿å­˜å¯¹è¯ç»“æœï¼Œå…ƒæ•°æ®: {result['metadata']}")
            
            # ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“
            logger.info(f"[MultiAgent] å¼€å§‹ä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“")
            logger.debug(f"[MultiAgent] å½“å‰ç”¨æˆ·: {current_user}, ç±»å‹: {type(current_user)}")
            logger.debug(f"[MultiAgent] å¯¹è¯ID: {conversation_id}")
            logger.debug(f"[MultiAgent] ç”¨æˆ·æ¶ˆæ¯: {request.message[:100]}...")
            logger.debug(f"[MultiAgent] AIå›å¤: {result['output'][:100]}...")  # åªæ‰“å°å‰100ä¸ªå­—ç¬¦
            
            if current_user and hasattr(current_user, 'user_id') and not getattr(current_user, 'is_anonymous', False):
                try:
                    conversation_service = ConversationService(db)
                    logger.debug(f"[MultiAgent] ConversationServiceå®ä¾‹åˆ›å»ºæˆåŠŸ")
                    
                    # ç¡®ä¿å¯¹è¯è®°å½•å­˜åœ¨
                    conversation = conversation_service.get_conversation(conversation_id)
                    if not conversation:
                        logger.info(f"[MultiAgent] åˆ›å»ºæ–°å¯¹è¯: {conversation_id}")
                        conversation = conversation_service.create_conversation(
                            conversation_id=conversation_id,
                            user_id=str(current_user.user_id),
                            title=request.message[:30] + ('...' if len(request.message) > 30 else '')
                        )
                        logger.info(f"[MultiAgent] å¯¹è¯åˆ›å»ºæˆåŠŸ: {conversation.conversation_id}")
                    else:
                        logger.debug(f"[MultiAgent] ä½¿ç”¨ç°æœ‰å¯¹è¯: {conversation_id}")
                    
                    # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
                    logger.debug(f"[MultiAgent] ä¿å­˜ç”¨æˆ·æ¶ˆæ¯åˆ°å¯¹è¯: {conversation_id}")
                    conversation_service.add_message(
                        conversation_id=conversation_id,
                        role="human",
                        content=request.message
                    )
                    logger.debug(f"[MultiAgent] ç”¨æˆ·æ¶ˆæ¯ä¿å­˜æˆåŠŸ")
                    
                    # ä¿å­˜AIå›å¤
                    logger.debug(f"[MultiAgent] ä¿å­˜AIå›å¤åˆ°å¯¹è¯: {conversation_id}")
                    conversation_service.add_message(
                        conversation_id=conversation_id,
                        role="assistant",
                        content=result["output"],
                        metadata=result.get("metadata", {})
                    )
                    logger.info(f"[MultiAgent] å¯¹è¯æ¶ˆæ¯ä¿å­˜å®Œæˆ")
                    
                    # æ›´æ–°ConversationBufferMemoryç¼“å­˜
                    try:
                        cache_key = f"{conversation_id}_{current_user.user_id or 'anonymous'}"
                        if cache_key in _buffer_memories:
                            buffer_memory = _buffer_memories[cache_key]
                            buffer_memory.chat_memory.add_user_message(request.message)
                            buffer_memory.chat_memory.add_ai_message(result["output"])
                            logger.debug(f"[MultiAgent] ConversationBufferMemoryç¼“å­˜å·²æ›´æ–°")
                    except Exception as e:
                        logger.error(f"[MultiAgent] æ›´æ–°ConversationBufferMemoryç¼“å­˜å¤±è´¥: {e}")
                    
                    # æ›´æ–°ç”¨æˆ·æƒ…ç»ªç”»åƒ
                    if emotion and emotion != "unknown":
                        logger.debug(f"[MultiAgent] å¼€å§‹æ›´æ–°ç”¨æˆ·æƒ…ç»ªç”»åƒ: emotion={emotion}, confidence={confidence}")
                        emotion_context = {
                            "conversation_id": conversation_id,
                            "message_content": request.message[:100],  # åªä¿å­˜å‰100ä¸ªå­—ç¬¦
                            "agent_details": result.get("metadata", {}).get("agent_details", {})
                        }
                        
                        emotion_updated = conversation_service.update_user_emotion_profile(
                            user_id=str(current_user.user_id),
                            emotion=emotion,
                            confidence=confidence,
                            emotion_context=emotion_context
                        )
                        
                        if emotion_updated:
                            logger.info(f"[MultiAgent] ç”¨æˆ·æƒ…ç»ªç”»åƒæ›´æ–°æˆåŠŸ: user_id={current_user.user_id}, emotion={emotion}")
                        else:
                            logger.warning(f"[MultiAgent] ç”¨æˆ·æƒ…ç»ªç”»åƒæ›´æ–°å¤±è´¥: user_id={current_user.user_id}")
                    else:
                        logger.debug(f"[MultiAgent] è·³è¿‡æƒ…ç»ªç”»åƒæ›´æ–°ï¼Œæƒ…ç»ªçŠ¶æ€ä¸º: {emotion}")
                    
                except Exception as e:
                    logger.error(f"[MultiAgent] ä¿å­˜å¯¹è¯å¤±è´¥: {e}")
                    logger.error(f"[MultiAgent] é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
                    # ä¸å½±å“å“åº”è¿”å›ï¼Œåªè®°å½•é”™è¯¯
                    pass
            else:
                logger.warning(f"[MultiAgent] ç”¨æˆ·æœªç™»å½•æˆ–ä¸ºåŒ¿åç”¨æˆ·ï¼Œè·³è¿‡å¯¹è¯ä¿å­˜")
            
            # æœ€ç»ˆå“åº”å·²åœ¨ä¸Šé¢çš„é€å­—è¾“å‡ºä¸­å‘é€ï¼Œè¿™é‡Œä¸éœ€è¦å†å‘é€
            yield "data: [DONE]\n\n"
            
        except Exception as e:
            logger.error(f"[API] æµå¼å“åº”ç”Ÿæˆå¼‚å¸¸: {e}")
            # ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œä¸è¿”å›é”™è¯¯å“åº”
            raise
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Conversation-ID": conversation_id  # æ·»åŠ å¯¹è¯IDåˆ°å“åº”å¤´
        }
    )

@router.get("/status", response_model=SystemStatusResponse)
async def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    try:
        # è¿™é‡Œå¯ä»¥æ·»åŠ å®é™…çš„å¥åº·æ£€æŸ¥é€»è¾‘
        # ä¾‹å¦‚æ£€æŸ¥LangChain Toolsæ˜¯å¦æ­£å¸¸å·¥ä½œ
        
        return SystemStatusResponse(
            tools_active=True,
            controller_active=True,
            database_active=True,
            vector_store_active=True,
            system_status="healthy"
        )
        
    except Exception as e:
        return SystemStatusResponse(
            tools_active=False,
            controller_active=False,
            database_active=False,
            vector_store_active=False,
            system_status=f"error: {str(e)}"
        )

@router.post("/analyze")
async def analyze_message(
    request: ChatRequest,
    current_user: User = Depends(get_current_user)
):
    """åˆ†ææ¶ˆæ¯ï¼ˆä»…åˆ†æï¼Œä¸ç”Ÿæˆå›å¤ï¼‰"""
    try:
        # ä½¿ç”¨åŸºäºLangChain Toolsçš„å¿ƒç†å’¨è¯¢æ§åˆ¶å™¨è¿›è¡Œåˆ†æ
        # å…·ä½“å®ç°è¯·å‚è€ƒ app/core/tools/psychological_controller.py
        
        # è¿™é‡Œå¯ä»¥æ·»åŠ ä»…åˆ†æçš„é€»è¾‘
        # ä¾‹å¦‚åªè¿è¡Œæ„å›¾åˆ†æå’Œå®‰å…¨æ£€æµ‹
        
        # ä¸´æ—¶è¿”å›æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…åº”ä½¿ç”¨ psychological_controller
        route_result = {
            "intent": "general_consultation",
            "confidence": 0.8,
            "explanation": "ç”¨æˆ·å¯»æ±‚ä¸€èˆ¬å¿ƒç†å’¨è¯¢"
        }
        
        crisis_assessment = {
            "risk_level": "low",
            "confidence": 0.9,
            "explanation": "æœªæ£€æµ‹åˆ°æ˜æ˜¾é£é™©"
        }
        
        return {
            "intent": route_result["intent"],
            "confidence": route_result["confidence"],
            "explanation": route_result["explanation"],
            "crisis_level": crisis_assessment["risk_level"],
            "crisis_confidence": crisis_assessment["confidence"],
            "crisis_explanation": crisis_assessment["explanation"],
            "requires_intervention": crisis_assessment["risk_level"] in ["high", "medium"],
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"æ¶ˆæ¯åˆ†æå¤±è´¥: {str(e)}"
        )

@router.get("/agents/info")
async def get_agents_info():
    """è·å–LangChain Toolsä¿¡æ¯ï¼ˆä¿æŒå‘åå…¼å®¹çš„è·¯å¾„ï¼‰"""
    return {
        "tools": [
            {
                "name": "Intent Analysis Tool",
                "description": "åˆ†æç”¨æˆ·è¾“å…¥æ„å›¾å¹¶ç¡®å®šå¤„ç†ç­–ç•¥",
                "capabilities": ["æ„å›¾è¯†åˆ«", "ç½®ä¿¡åº¦è¯„ä¼°", "è·¯ç”±å†³ç­–"]
            },
            {
                "name": "Safety Check Tool",
                "description": "è¯†åˆ«è‡ªä¼¤ã€è‡ªæ€ç­‰é«˜é£é™©å†…å®¹ï¼Œè°ƒç”¨å®‰å…¨æµç¨‹",
                "capabilities": ["å±æœºæ£€æµ‹", "é£é™©è¯„ä¼°", "å®‰å…¨å¹²é¢„"]
            },
            {
                "name": "Document Retrieval Tool",
                "description": "è´Ÿè´£å‘ChromaDBæ‰§è¡Œå‘é‡æ£€ç´¢ä¸å…³é”®è¯æ£€ç´¢",
                "capabilities": ["å‘é‡æ£€ç´¢", "å…³é”®è¯æ£€ç´¢", "RRFèåˆ"]
            },
            {
                "name": "Document Reranking Tool",
                "description": "å¯¹æ£€ç´¢ç»“æœè¿›è¡ŒCross-Encoderç²¾æ’",
                "capabilities": ["æ–‡æ¡£é‡æ’åº", "ç›¸å…³æ€§è¯„åˆ†", "ç»“æœä¼˜åŒ–"]
            },
            {
                "name": "Answer Generation Tool",
                "description": "åŸºäºæ£€ç´¢ç»“æœå’Œç”¨æˆ·æƒ…ç»ªç”Ÿæˆæœ€ç»ˆå›å¤",
                "capabilities": ["æƒ…ç»ªåˆ†æ", "å›å¤ç”Ÿæˆ", "æƒ…ç»ªæ”¯æŒ"]
            }
        ],
        "workflow": {
            "description": "ç”¨æˆ·è¾“å…¥ â†’ æ„å›¾åˆ†æ â†’ å®‰å…¨æ£€æµ‹ â†’ æ–‡æ¡£æ£€ç´¢ â†’ æ–‡æ¡£é‡æ’åº â†’ ç­”æ¡ˆç”Ÿæˆ",
            "features": ["LangChain Toolsæ¶æ„", "å®‰å…¨æ£€æµ‹", "çŸ¥è¯†æ£€ç´¢", "æƒ…ç»ªæ”¯æŒ", "ä¸ªæ€§åŒ–å›å¤"]
        }
    }