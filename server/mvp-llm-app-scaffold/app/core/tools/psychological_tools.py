"""å¿ƒç†å¥åº·èŠå¤©æœºå™¨äººçš„å·¥å…·é›†åˆ - åŸºäºLangChain Toolsçš„ç‹¬ç«‹å®ç°"""

from typing import Dict, Any, List, Optional
from langchain_core.tools import tool
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
import logging
from app.core.factories import create_llm_instance
from app.core.vector_store import get_vector_store
from langchain_core.documents import Document
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

logger = logging.getLogger(__name__)


class IntentAnalysisInput(BaseModel):
    """æ„å›¾åˆ†æå·¥å…·è¾“å…¥æ¨¡å‹"""
    args: Dict[str, Any] = Field(description="åŒ…å«user_inputå’Œchat_historyçš„å‚æ•°å­—å…¸")


class SafetyCheckInput(BaseModel):
    """å®‰å…¨æ£€æŸ¥å·¥å…·è¾“å…¥æ¨¡å‹"""
    args: Dict[str, Any] = Field(description="åŒ…å«user_inputå’Œchat_historyçš„å‚æ•°å­—å…¸")


class DocumentRetrievalInput(BaseModel):
    """æ–‡æ¡£æ£€ç´¢å·¥å…·è¾“å…¥æ¨¡å‹"""
    args: Dict[str, Any] = Field(description="åŒ…å«user_inputã€intentå’Œchat_historyçš„å‚æ•°å­—å…¸")


class DocumentRerankInput(BaseModel):
    """æ–‡æ¡£é‡æ’åºå·¥å…·è¾“å…¥æ¨¡å‹"""
    args: Dict[str, Any] = Field(description="åŒ…å«user_inputå’Œdocumentsçš„å‚æ•°å­—å…¸")


class AnswerGenerationInput(BaseModel):
    """ç­”æ¡ˆç”Ÿæˆå·¥å…·è¾“å…¥æ¨¡å‹"""
    args: Dict[str, Any] = Field(description="åŒ…å«user_inputã€intentã€documentsã€chat_historyå’Œsafety_triggeredçš„å‚æ•°å­—å…¸")


@tool(args_schema=IntentAnalysisInput)
def analyze_intent(args: Dict[str, Any]) -> Dict[str, Any]:
    """åˆ†æç”¨æˆ·è¾“å…¥çš„æ„å›¾å’Œæƒ…ç»ªçŠ¶æ€"""
    try:
        user_input = args.get("user_input", "")
        chat_history = args.get("chat_history", [])
        
        logger.info(f"[IntentAnalysisTool] å¼€å§‹æ„å›¾åˆ†æ: {user_input[:50]}...")
        
        # ç®€å•çš„æ„å›¾åˆ†æé€»è¾‘
        crisis_keywords = ["æƒ³æ­»", "è‡ªæ€", "ç»“æŸç”Ÿå‘½", "ä¸æƒ³æ´»", "æ­»äº†ç®—äº†", "è‡ªæ®‹", "è‡ªä¼¤"]
        consultation_keywords = ["ç„¦è™‘", "æŠ‘éƒ", "å‹åŠ›", "å›°æ‰°", "å¸®åŠ©", "éš¾è¿‡", "ç—›è‹¦"]
        knowledge_keywords = ["ä»€ä¹ˆæ˜¯", "å¦‚ä½•", "ä¸ºä»€ä¹ˆ", "è§£é‡Š", "äº†è§£", "æˆ‘æ˜¯è°", "æˆ‘æ˜¯", "å…³äºæˆ‘", "ä¸ªäººä¿¡æ¯", "æˆ‘çš„", "ä»‹ç»ä¸€ä¸‹", "å‘Šè¯‰æˆ‘"]
        
        if any(keyword in user_input for keyword in crisis_keywords):
            intent = "crisis"
            confidence = 0.9
        elif any(keyword in user_input for keyword in consultation_keywords):
            intent = "consultation"
            confidence = 0.8
        elif any(keyword in user_input for keyword in knowledge_keywords):
            intent = "knowledge"
            confidence = 0.7
        else:
            intent = "chat"
            confidence = 0.6
        
        result = {
            "intent": intent,
            "confidence": confidence,
            "reasoning": f"åŸºäºå…³é”®è¯åˆ†æç¡®å®šæ„å›¾ä¸º{intent}",
            "next_step": "safety_check" if intent == "crisis" else "document_retrieval",
            "user_input": user_input,
            "chat_history": chat_history or []
        }
        
        logger.info(f"[IntentAnalysisTool] æ„å›¾åˆ†æå®Œæˆ: {intent}, ç½®ä¿¡åº¦: {confidence}")
        return result
        
    except Exception as e:
        logger.error(f"[IntentAnalysisTool] æ„å›¾åˆ†æå¤±è´¥: {e}")
        return {
            "intent": "consultation",
            "confidence": 0.5,
            "reasoning": f"æ„å›¾åˆ†æå¤±è´¥ï¼Œé»˜è®¤ä¸ºå’¨è¯¢æ„å›¾ã€‚é”™è¯¯ï¼š{str(e)}",
            "next_step": "document_retrieval",
            "user_input": user_input,
            "chat_history": chat_history or []
        }


@tool(args_schema=SafetyCheckInput)
def check_safety(args: Dict[str, Any]) -> Dict[str, Any]:
    """æ£€æŸ¥ç”¨æˆ·è¾“å…¥æ˜¯å¦åŒ…å«è‡ªä¼¤ã€è‡ªæ€æˆ–å…¶ä»–å±é™©å†…å®¹"""
    try:
        user_input = args.get("user_input", "")
        chat_history = args.get("chat_history", [])
        
        logger.info(f"[SafetyCheckTool] å¼€å§‹å®‰å…¨æ£€æŸ¥: {user_input[:50]}...")
        
        crisis_resources = {
            "hotlines": [
                "å…¨å›½å¿ƒç†å±æœºå¹²é¢„çƒ­çº¿ï¼š400-161-9995",
                "åŒ—äº¬å±æœºå¹²é¢„çƒ­çº¿ï¼š400-161-9995",
                "ä¸Šæµ·å¿ƒç†æ´åŠ©çƒ­çº¿ï¼š021-34289888",
                "å¹¿å·å¿ƒç†å±æœºå¹²é¢„çƒ­çº¿ï¼š020-81899120"
            ],
            "emergency": "å¦‚æœæƒ…å†µç´§æ€¥ï¼Œè¯·ç«‹å³æ‹¨æ‰“120æ€¥æ•‘ç”µè¯æˆ–å‰å¾€æœ€è¿‘çš„åŒ»é™¢æ€¥è¯Šç§‘"
        }
        
        # é«˜é£é™©å…³é”®è¯æ£€æµ‹
        high_risk_keywords = ["è‡ªæ€", "æƒ³æ­»", "ç»“æŸç”Ÿå‘½", "ä¸æƒ³æ´»", "æ­»äº†ç®—äº†", "è‡ªæ®‹", "è‡ªä¼¤", "å‰²è…•", "è·³æ¥¼"]
        medium_risk_keywords = ["ç»æœ›", "æ— åŠ©", "æ²¡æœ‰æ„ä¹‰", "æ´»ç€æ²¡æ„æ€", "ç—›è‹¦", "æŠ˜ç£¨"]
        
        high_risk_count = sum(1 for keyword in high_risk_keywords if keyword in user_input)
        medium_risk_count = sum(1 for keyword in medium_risk_keywords if keyword in user_input)
        
        if high_risk_count > 0:
            risk_level = "high"
            immediate_action = True
            confidence = 0.9
            response = f"æˆ‘éå¸¸å…³å¿ƒæ‚¨çš„å®‰å…¨ã€‚è¯·ç«‹å³è”ç³»ä¸“ä¸šå¸®åŠ©ï¼š\n\n{crisis_resources['emergency']}\n\nå¿ƒç†å±æœºå¹²é¢„çƒ­çº¿ï¼š\n" + "\n".join(crisis_resources['hotlines'])
        elif medium_risk_count > 0:
            risk_level = "medium"
            immediate_action = True
            confidence = 0.7
            response = "æˆ‘æ³¨æ„åˆ°æ‚¨å¯èƒ½æ­£åœ¨ç»å†å›°éš¾æ—¶æœŸã€‚å»ºè®®æ‚¨å¯»æ±‚ä¸“ä¸šå¿ƒç†å¥åº·æ”¯æŒã€‚å¦‚éœ€ç´§æ€¥å¸®åŠ©ï¼Œè¯·è”ç³»å¿ƒç†å±æœºå¹²é¢„çƒ­çº¿ï¼š400-161-9995"
        else:
            risk_level = "low"
            immediate_action = False
            confidence = 0.8
            response = None
        
        result = {
            "risk_level": risk_level,
            "risk_factors": high_risk_keywords + medium_risk_keywords if high_risk_count + medium_risk_count > 0 else [],
            "immediate_action_required": immediate_action,
            "confidence": confidence,
            "reasoning": f"æ£€æµ‹åˆ°{high_risk_count}ä¸ªé«˜é£é™©å…³é”®è¯ï¼Œ{medium_risk_count}ä¸ªä¸­é£é™©å…³é”®è¯",
            "response": response,
            "requires_human_intervention": immediate_action,
            "next_step": "end" if immediate_action else "document_retrieval"
        }
        
        logger.info(f"[SafetyCheckTool] å®‰å…¨æ£€æŸ¥å®Œæˆ: é£é™©ç­‰çº§={risk_level}, éœ€è¦å¹²é¢„={immediate_action}")
        return result
        
    except Exception as e:
        logger.error(f"[SafetyCheckTool] å®‰å…¨æ£€æŸ¥å¤±è´¥: {e}")
        return {
            "risk_level": "medium",
            "risk_factors": ["å®‰å…¨æ£€æŸ¥ç³»ç»Ÿå¼‚å¸¸"],
            "immediate_action_required": True,
            "confidence": 0.5,
            "reasoning": f"å®‰å…¨æ£€æŸ¥å¤±è´¥ï¼Œå‡ºäºå®‰å…¨è€ƒè™‘æ ‡è®°ä¸ºä¸­ç­‰é£é™©ã€‚é”™è¯¯ï¼š{str(e)}",
            "response": "æˆ‘æ£€æµ‹åˆ°å¯èƒ½å­˜åœ¨å®‰å…¨é£é™©ï¼Œå»ºè®®æ‚¨è”ç³»ä¸“ä¸šçš„å¿ƒç†å¥åº·æœåŠ¡ã€‚å¦‚æœæƒ…å†µç´§æ€¥ï¼Œè¯·æ‹¨æ‰“å¿ƒç†å±æœºå¹²é¢„çƒ­çº¿ï¼š400-161-9995",
            "requires_human_intervention": True,
            "next_agent": "end"
        }


@tool(args_schema=DocumentRetrievalInput)
def retrieve_documents(args: Dict[str, Any]) -> Dict[str, Any]:
    """æ ¹æ®ç”¨æˆ·è¾“å…¥å’Œæ„å›¾æ£€ç´¢ç›¸å…³çš„å¿ƒç†å¥åº·çŸ¥è¯†æ–‡æ¡£"""
    try:
        user_input = args.get("user_input", "")
        intent = args.get("intent", "consultation")
        chat_history = args.get("chat_history", [])
        
        logger.info(f"[DocumentRetrievalTool] å¼€å§‹æ–‡æ¡£æ£€ç´¢: æ„å›¾={intent}, æŸ¥è¯¢={user_input[:50]}...")
        
        vector_store = get_vector_store()
        
        # æ ¹æ®æ„å›¾è°ƒæ•´æ£€ç´¢ç­–ç•¥
        if intent == "crisis":
            k = 3  # å±æœºæƒ…å†µä¸‹æ£€ç´¢è¾ƒå°‘æ–‡æ¡£ï¼Œå¿«é€Ÿå“åº”
        elif intent == "knowledge":
            k = 8  # çŸ¥è¯†æŸ¥è¯¢éœ€è¦æ›´å¤šç›¸å…³æ–‡æ¡£
        else:
            k = 5  # é»˜è®¤æ£€ç´¢æ•°é‡
        
        # æ‰§è¡Œå‘é‡æ£€ç´¢
        docs = vector_store.similarity_search(user_input, k=k)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        retrieved_documents = []
        for i, doc in enumerate(docs):
            retrieved_documents.append({
                "content": doc.page_content,
                "metadata": doc.metadata,
                "score": getattr(doc, "score", 0.0),
                "rank": i + 1,
                "source": "vector_search"
            })
        
        result = {
            "retrieved_documents": retrieved_documents,
            "next_step": "document_rerank" if len(retrieved_documents) > 3 else "answer_generation",
            "retrieval_method": "vector_search",
            "document_count": len(retrieved_documents)
        }
        
        logger.info(f"[DocumentRetrievalTool] æ–‡æ¡£æ£€ç´¢å®Œæˆ: æ£€ç´¢åˆ°{len(retrieved_documents)}ä¸ªæ–‡æ¡£")
        return result
        
    except Exception as e:
        logger.error(f"[DocumentRetrievalTool] æ–‡æ¡£æ£€ç´¢å¤±è´¥: {e}")
        return {
            "retrieved_documents": [],
            "next_step": "answer_generation",
            "error": f"æ–‡æ¡£æ£€ç´¢å¤±è´¥ï¼š{str(e)}",
            "document_count": 0
        }


@tool(args_schema=DocumentRerankInput)
def rerank_documents(args: Dict[str, Any]) -> Dict[str, Any]:
    """å¯¹æ£€ç´¢åˆ°çš„æ–‡æ¡£è¿›è¡Œé‡æ’åºï¼Œæé«˜ç›¸å…³æ€§"""
    try:
        user_input = args.get("user_input", "")
        documents = args.get("documents", [])
        
        logger.info(f"[DocumentRerankTool] å¼€å§‹æ–‡æ¡£é‡æ’åº: {len(documents)}ä¸ªæ–‡æ¡£")
        
        if not documents:
            return {
                 "reranked_documents": [],
                 "next_step": "answer_generation",
                 "rerank_method": "none"
             }
        
        tfidf_vectorizer = TfidfVectorizer(max_features=1000, ngram_range=(1, 2))
        
        # é¢„å¤„ç†æŸ¥è¯¢å’Œæ–‡æ¡£
        query_tokens = list(jieba.cut(user_input))
        query_text = " ".join(query_tokens)
        
        doc_texts = []
        for doc in documents:
            content = doc.get("content", "")
            tokens = list(jieba.cut(content))
            doc_texts.append(" ".join(tokens))
        
        # ä½¿ç”¨TF-IDFè®¡ç®—ç›¸ä¼¼åº¦
        all_texts = [query_text] + doc_texts
        tfidf_matrix = tfidf_vectorizer.fit_transform(all_texts)
        
        query_vector = tfidf_matrix[0:1]
        doc_vectors = tfidf_matrix[1:]
        similarities = cosine_similarity(query_vector, doc_vectors)[0]
        
        # é‡æ–°æ’åºæ–‡æ¡£
        scored_docs = []
        for i, (doc, score) in enumerate(zip(documents, similarities)):
            scored_docs.append({
                **doc,
                "relevance_score": float(score),
                "original_rank": doc.get("rank", i + 1),
                "rerank_score": float(score)
            })
        
        # æŒ‰ç›¸å…³æ€§åˆ†æ•°æ’åº
        scored_docs.sort(key=lambda x: x["relevance_score"], reverse=True)
        
        # æ›´æ–°æ’å
        for i, doc in enumerate(scored_docs):
            doc["rank"] = i + 1
        
        result = {
             "reranked_documents": scored_docs[:5],  # è¿”å›å‰5ä¸ªæœ€ç›¸å…³çš„æ–‡æ¡£
             "next_step": "answer_generation",
             "rerank_method": "tfidf_cosine",
             "original_count": len(documents),
             "reranked_count": len(scored_docs[:5])
         }
        
        logger.info(f"[DocumentRerankTool] æ–‡æ¡£é‡æ’åºå®Œæˆ: {len(scored_docs[:5])}ä¸ªæ–‡æ¡£")
        return result
        
    except Exception as e:
        logger.error(f"[DocumentRerankTool] æ–‡æ¡£é‡æ’åºå¤±è´¥: {e}")
        return {
             "reranked_documents": documents[:5],  # å¦‚æœé‡æ’åºå¤±è´¥ï¼Œè¿”å›å‰5ä¸ªåŸå§‹æ–‡æ¡£
             "next_step": "answer_generation",
             "error": f"æ–‡æ¡£é‡æ’åºå¤±è´¥ï¼š{str(e)}",
             "rerank_method": "fallback"
         }


@tool(args_schema=AnswerGenerationInput)
def generate_answer(args: Dict[str, Any]) -> Dict[str, Any]:
    """åŸºäºç”¨æˆ·è¾“å…¥ã€æ„å›¾å’Œç›¸å…³æ–‡æ¡£ç”Ÿæˆæœ€ç»ˆå›å¤"""
    try:
        user_input = args.get("user_input", "")
        intent = args.get("intent", "consultation")
        documents = args.get("documents", [])
        chat_history = args.get("chat_history", [])
        safety_triggered = args.get("safety_triggered", False)
        
        logger.info(f"[AnswerGenerationTool] å¼€å§‹ç”Ÿæˆç­”æ¡ˆ: æ„å›¾={intent}, æ–‡æ¡£æ•°={len(documents or [])}, å®‰å…¨è§¦å‘={safety_triggered}")
        
        # å¦‚æœå®‰å…¨æœºåˆ¶å·²è§¦å‘ï¼Œç›´æ¥è¿”å›å®‰å…¨å›å¤
        if safety_triggered:
            return {
                 "final_response": "æˆ‘éå¸¸å…³å¿ƒæ‚¨çš„å®‰å…¨å’Œç¦ç¥‰ã€‚è¯·è€ƒè™‘è”ç³»ä¸“ä¸šçš„å¿ƒç†å¥åº·æœåŠ¡æˆ–å±æœºå¹²é¢„çƒ­çº¿ã€‚æ‚¨çš„ç”Ÿå‘½å¾ˆå®è´µï¼Œæ€»æœ‰äººæ„¿æ„å¸®åŠ©æ‚¨ã€‚",
                 "response_type": "safety_intervention",
                 "confidence": 1.0,
                 "next_step": "end"
             }
        
        llm = create_llm_instance()
        prompt = ChatPromptTemplate.from_messages([
            ("system", """ä½ æ˜¯ä¸€ä½ä¸“ä¸šã€æ¸©æš–ã€æœ‰åŒç†å¿ƒçš„AIå¿ƒç†å¥åº·åŠ©æ‰‹ã€‚è¯·æ ¹æ®ç”¨æˆ·çš„è¾“å…¥ã€æ„å›¾å’Œç›¸å…³æ–‡æ¡£ç”Ÿæˆä¸€ä¸ªåŒ…å«æ€è€ƒè¿‡ç¨‹çš„ä¸“ä¸šå›å¤ã€‚

å›å¤ç»“æ„è¦æ±‚ï¼š
1. é¦–å…ˆè¡¨è¾¾å¯¹ç”¨æˆ·çš„ç†è§£å’Œå…±æƒ…
2. ç®€è¦åˆ†æç”¨æˆ·çš„æƒ…å†µï¼ˆåŸºäºæ„å›¾å’Œæƒ…ç»ªï¼‰
3. æä¾›ä¸“ä¸šçš„å»ºè®®æˆ–æ”¯æŒ
4. å¦‚æœæœ‰ç›¸å…³æ–‡æ¡£ï¼Œè¦è‡ªç„¶åœ°èå…¥å›å¤ä¸­
5. ä»¥é¼“åŠ±å’Œæ”¯æŒçš„è¯è¯­ç»“æŸ

å›å¤åŸåˆ™ï¼š
â€¢ ä¿æŒä¸“ä¸šæ€§å’ŒåŒç†å¿ƒ
â€¢ æ ¹æ®ç”¨æˆ·æ„å›¾è°ƒæ•´å›å¤é£æ ¼
â€¢ é¿å…è¯Šæ–­æˆ–æä¾›åŒ»ç–—å»ºè®®
â€¢ é¼“åŠ±ç”¨æˆ·å¯»æ±‚ä¸“ä¸šå¸®åŠ©
â€¢ ä¿æŒæ¸©æš–ã€æ”¯æŒæ€§çš„è¯­è°ƒ
â€¢ ä½“ç°AIçš„åˆ†ææ€è·¯å’Œä¸“ä¸šåˆ¤æ–­

å½“å‰åˆ†æï¼š
- ç”¨æˆ·æ„å›¾ï¼š{intent}
- æƒ…ç»ªçŠ¶æ€ï¼šéœ€è¦ä»ç”¨æˆ·è¾“å…¥ä¸­è¯†åˆ«
- ç›¸å…³æ–‡æ¡£ï¼š{documents}
- å¯¹è¯å†å²ï¼š{chat_history}
- å®‰å…¨çŠ¶æ€ï¼š{safety_triggered}

è¯·ç”Ÿæˆä¸€ä¸ªæ—¢ä¸“ä¸šåˆæ¸©æš–çš„å›å¤ï¼Œè®©ç”¨æˆ·æ„Ÿå—åˆ°è¢«ç†è§£å’Œæ”¯æŒã€‚"""),
            ("human", "ç”¨æˆ·è¾“å…¥ï¼š{user_input}")
        ])
        
        # å‡†å¤‡æ–‡æ¡£å†…å®¹
        doc_content = ""
        if documents:
            doc_content = "\n\n".join([doc.get("content", "")[:500] for doc in documents[:3]])
        
        # å‡†å¤‡å¯¹è¯å†å²
        history_text = ""
        if chat_history:
            recent_history = chat_history[-3:]  # åªä½¿ç”¨æœ€è¿‘3è½®å¯¹è¯
            history_text = "\n".join([f"{msg.get('role', 'user')}: {msg.get('content', '')}" for msg in recent_history])
        
        # ç”Ÿæˆå›å¤
        logger.info(f"[AnswerGenerationTool] å‡†å¤‡è°ƒç”¨LLMï¼Œç”¨æˆ·è¾“å…¥: {user_input[:100]}...")
        logger.info(f"[AnswerGenerationTool] æ–‡æ¡£å†…å®¹é•¿åº¦: {len(doc_content)}")
        
        try:
            formatted_messages = prompt.format_messages(
                user_input=user_input,
                intent=intent,
                documents=doc_content or "æ— ç›¸å…³æ–‡æ¡£",
                chat_history=history_text or "æ— å¯¹è¯å†å²",
                safety_triggered=safety_triggered
            )
            logger.info(f"[AnswerGenerationTool] æ¶ˆæ¯æ ¼å¼åŒ–å®Œæˆï¼Œå¼€å§‹è°ƒç”¨LLM")
            
            response = llm.invoke(formatted_messages)
            logger.info(f"[AnswerGenerationTool] LLMè°ƒç”¨æˆåŠŸï¼Œå“åº”ç±»å‹: {type(response)}")
            
            final_response = response.content if hasattr(response, 'content') else str(response)
            logger.info(f"[AnswerGenerationTool] æœ€ç»ˆå›å¤é•¿åº¦: {len(final_response)}")
            
        except Exception as llm_error:
            logger.error(f"[AnswerGenerationTool] LLMè°ƒç”¨å¤±è´¥: {llm_error}")
            logger.error(f"[AnswerGenerationTool] LLMé”™è¯¯è¯¦æƒ…: {type(llm_error).__name__}: {str(llm_error)}")
            import traceback
            logger.error(f"[AnswerGenerationTool] LLMé”™è¯¯å †æ ˆ: {traceback.format_exc()}")
            
            # LLMè°ƒç”¨å¤±è´¥æ—¶çš„å¤‡ç”¨å›å¤
            final_response = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ä¸ºæ‚¨æä¾›è¯¦ç»†çš„å›å¤ã€‚å»ºè®®æ‚¨ç¨åå†è¯•ï¼Œæˆ–ç›´æ¥è”ç³»ä¸“ä¸šçš„å¿ƒç†å¥åº·æœåŠ¡ã€‚"
            logger.warning(f"[AnswerGenerationTool] ä½¿ç”¨å¤‡ç”¨å›å¤")
        
        # åˆ†æç”¨æˆ·æƒ…ç»ª
        emotion = "neutral"
        emotion_keywords = {
            "anxious": ["ç„¦è™‘", "æ‹…å¿ƒ", "ç´§å¼ ", "ä¸å®‰", "ææƒ§"],
            "sad": ["éš¾è¿‡", "ä¼¤å¿ƒ", "æ²®ä¸§", "å¤±è½", "ç—›è‹¦", "ç»æœ›"],
            "angry": ["æ„¤æ€’", "ç”Ÿæ°”", "æ¼ç«", "çƒ¦èº", "æ„¤æ¨"],
            "confused": ["å›°æƒ‘", "è¿·èŒ«", "ä¸çŸ¥é“", "ä¸æ˜ç™½", "ç–‘æƒ‘"],
            "hopeful": ["å¸Œæœ›", "æœŸå¾…", "ä¹è§‚", "ç§¯æ", "å‘ä¸Š"]
        }
        
        for emotion_type, keywords in emotion_keywords.items():
            if any(keyword in user_input for keyword in keywords):
                emotion = emotion_type
                break
        
        # æ ¹æ®æ„å›¾å’Œæƒ…ç»ªæ·»åŠ é€‚å½“çš„ç»“å°¾
        if intent == "consultation":
            if emotion in ["sad", "anxious"]:
                final_response += "\n\nğŸ’™ è¯·è®°ä½ï¼Œæ‚¨å¹¶ä¸å­¤å•ã€‚å¦‚æœéœ€è¦æ›´ä¸“ä¸šçš„å¸®åŠ©ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šçš„å¿ƒç†å¥åº·ä¸“å®¶ã€‚"
            else:
                final_response += "\n\nå¦‚æœæ‚¨éœ€è¦æ›´ä¸“ä¸šçš„å¸®åŠ©ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šçš„å¿ƒç†å¥åº·ä¸“å®¶ã€‚"
        elif intent == "knowledge":
            final_response += "\n\nğŸ“š å¸Œæœ›è¿™äº›ä¿¡æ¯å¯¹æ‚¨æœ‰å¸®åŠ©ã€‚å¦‚æœ‰æ›´å¤šç–‘é—®ï¼Œæ¬¢è¿ç»§ç»­è¯¢é—®ã€‚"
        elif intent == "crisis":
            final_response += "\n\nğŸ†˜ æ‚¨çš„å®‰å…¨æ˜¯æœ€é‡è¦çš„ã€‚è¯·ç«‹å³å¯»æ±‚ä¸“ä¸šå¸®åŠ©æˆ–è”ç³»å±æœºå¹²é¢„çƒ­çº¿ã€‚"
        
        result = {
             "final_response": final_response,
             "response_type": intent,
             "emotion": emotion,
             "confidence": 0.8,
             "used_documents": len(documents or []),
             "next_step": "end"
         }
        
        logger.info(f"[AnswerGenerationTool] ç­”æ¡ˆç”Ÿæˆå®Œæˆ: å›å¤é•¿åº¦={len(final_response)}")
        return result
        
    except Exception as e:
        logger.error(f"[AnswerGenerationTool] ç­”æ¡ˆç”Ÿæˆå¤±è´¥: {e}")
        return {
             "final_response": "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•ä¸ºæ‚¨æä¾›å›å¤ã€‚å»ºè®®æ‚¨ç¨åå†è¯•ï¼Œæˆ–ç›´æ¥è”ç³»ä¸“ä¸šçš„å¿ƒç†å¥åº·æœåŠ¡ã€‚",
             "response_type": "error",
             "confidence": 0.0,
             "error": str(e),
             "next_step": "end"
         }